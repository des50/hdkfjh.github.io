WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:05.099
In this demo, we're going to create a DAG that uses a subDAG.

00:00:05.099 --> 00:00:09.914
You'll see how to populate a subDAG and instantiate it in your own DAGs.

00:00:09.914 --> 00:00:13.199
So, we're going to return to the homepage of Airflow,

00:00:13.199 --> 00:00:15.750
and then we're going to jump back to the code.

00:00:15.750 --> 00:00:21.089
First thing I'm going to do is I'm going to open the folder lesson3.demo3.

00:00:21.089 --> 00:00:24.989
I just want to stop for a moment and point out that in your exercise you will have

00:00:24.989 --> 00:00:28.919
an exercise3 folder, not an exercise3.py.

00:00:28.920 --> 00:00:32.325
So, expect to see a folder called exercise3.

00:00:32.325 --> 00:00:38.085
Then this folder, you're going to see two files: dag.py and subdag.py.

00:00:38.085 --> 00:00:40.410
Let's first look at our DAG.

00:00:40.409 --> 00:00:44.689
So, you'll see this DAG looks fairly standard so far.

00:00:44.689 --> 00:00:46.744
We have a DAG definition.

00:00:46.744 --> 00:00:52.324
But almost immediately, you'll see that we have something called a SubDagOperator,

00:00:52.325 --> 00:00:54.875
which is something that we haven't seen before.

00:00:54.875 --> 00:00:57.725
I'm going to show you how we created the subDAG in a moment,

00:00:57.725 --> 00:01:00.484
but I first wanted to show you how it gets used in the DAG.

00:01:00.484 --> 00:01:04.924
So, the first thing to point out here is that we've imported the SubDagOperator.

00:01:04.924 --> 00:01:06.909
You can see this on line five.

00:01:06.909 --> 00:01:11.465
So, a SubDagOperator is much like other operators we've talked about in this class,

00:01:11.465 --> 00:01:14.555
such as PostgresOperator or Python operator,

00:01:14.555 --> 00:01:17.705
but the important thing to keep in mind is that

00:01:17.704 --> 00:01:22.939
the SubDagOperator is actually calling a Python factory function.

00:01:22.939 --> 00:01:25.429
In the case of line 22,

00:01:25.430 --> 00:01:29.690
it's calling the get_s3_to_redshift_dag function to return a DAG.

00:01:29.689 --> 00:01:35.450
So, this operator is actually executing an entire DAG.

00:01:35.450 --> 00:01:38.579
We'll get into these arguments here in just a moment.

00:01:38.579 --> 00:01:40.340
For now, we can just ignore them.

00:01:40.340 --> 00:01:42.500
Let's go take a look at our subDAG.

00:01:42.500 --> 00:01:47.859
So, again, lesson3.demo3, we're going to open subdag.py.

00:01:47.859 --> 00:01:49.364
If this was your exercise,

00:01:49.364 --> 00:01:53.549
you would open lesson3.exercise3, subdag.py.

00:01:53.549 --> 00:01:56.644
In here, you're going to see a number of things to find

00:01:56.644 --> 00:01:59.664
that look somewhat familiar once we finish the demonstration.

00:01:59.665 --> 00:02:03.920
At this point, we've only defined a function that takes a number of arguments.

00:02:03.920 --> 00:02:07.670
This function get_s3_to_redshift_dag and returns it.

00:02:07.670 --> 00:02:11.485
So, you can see we have another DAG defined in here.

00:02:11.485 --> 00:02:13.725
So, even though this is a function,

00:02:13.724 --> 00:02:18.180
it is actually defining and returning a DAG.

00:02:18.610 --> 00:02:20.795
It's also worth mentioning,

00:02:20.794 --> 00:02:22.699
and this is very important that we have

00:02:22.699 --> 00:02:26.629
the DAG name defined as the parent_dag_name.task_id.

00:02:28.909 --> 00:02:33.270
You must name your subDAGs following this pattern.

00:02:33.270 --> 00:02:36.275
Airflow will actually throw an error if you don't follow this pattern.

00:02:36.275 --> 00:02:40.340
So, again, the name of your subDAGs must always be the name of

00:02:40.340 --> 00:02:48.129
the parent DAG dot the name of the new task ID.

00:02:48.169 --> 00:02:51.079
All right. So, now that we've done that,

00:02:51.080 --> 00:02:56.020
we're going to actually start to combine the functionality from our DAG into the subDAG.

00:02:56.020 --> 00:02:57.235
So, I'm going to open,

00:02:57.235 --> 00:02:58.660
I'm going to do a split window here.

00:02:58.659 --> 00:03:02.719
I'm going to open this DAG below so we can start moving the code around.

00:03:04.219 --> 00:03:08.155
So, on the top window here where I'm moving the cursor,

00:03:08.155 --> 00:03:09.474
this is our subDAG,

00:03:09.474 --> 00:03:13.879
and you can see that on the middle section here it says dags/lesson3/demo3/subdag.py.

00:03:14.490 --> 00:03:18.100
The bottom code, this is our Dag.

00:03:18.099 --> 00:03:22.210
We want to move some of the code from the this DAG into our subDAG.

00:03:22.210 --> 00:03:24.820
So, we're going to move down here,

00:03:24.819 --> 00:03:29.034
and we're going to move the create_table code into our subDAG.

00:03:29.034 --> 00:03:32.305
So, I'm going to just grab this,

00:03:32.305 --> 00:03:35.050
copy and create code,

00:03:35.050 --> 00:03:41.230
and I'm going to paste it in.

00:03:41.960 --> 00:03:46.069
Now, we're not done quite yet because this is specific,

00:03:46.068 --> 00:03:48.844
this code is specifically formatted for the trips_table.

00:03:48.844 --> 00:03:54.484
The whole point of a subDAG is that it's supposed to be reusable.

00:03:54.485 --> 00:03:58.180
So, if we wrote a subDAG that just works on trips_table,

00:03:58.180 --> 00:04:00.365
that really wouldn't be very useful.

00:04:00.365 --> 00:04:03.920
So, the first thing we need to do is go back and look at our arguments.

00:04:03.919 --> 00:04:07.280
Here, we'll notice that we have a table, we have our bucket,

00:04:07.280 --> 00:04:09.710
key, all of the arguments that we actually

00:04:09.710 --> 00:04:13.189
need to instantiate the operators this task uses.

00:04:13.189 --> 00:04:15.365
So, I'm going to scroll down here.

00:04:15.365 --> 00:04:17.345
We're going to go ahead and give this task_id,

00:04:17.345 --> 00:04:20.210
we're going to turn this into a formatter.

00:04:20.209 --> 00:04:28.209
So, we're going to use Python formatting to say, create_table argument table.

00:04:28.209 --> 00:04:35.449
The DAG, we want that to be the DAG that we defined within our subDAG on line 25.

00:04:35.509 --> 00:04:39.550
Next, we need to pass in a Postgres connection ID,

00:04:39.550 --> 00:04:41.470
but we can't be sure that it's going to be redshift.

00:04:41.470 --> 00:04:43.300
Maybe we want to talk to a different cluster

00:04:43.300 --> 00:04:45.449
or different database altogether and a subDAG.

00:04:45.449 --> 00:04:47.139
We can't make those kinds of assumptions.

00:04:47.139 --> 00:04:49.810
So, we need to go up here and grab

00:04:49.810 --> 00:04:56.120
the redshift connection ID variable and fill it in for our Postgres connection ID.

00:04:56.310 --> 00:05:01.660
Finally and importantly, we don't know what SQL we need to execute.

00:05:01.660 --> 00:05:05.520
Who knows what the create_trips SQL might look like.

00:05:05.990 --> 00:05:08.345
So, to do that,

00:05:08.345 --> 00:05:10.625
we need to grab this create SQL statement,

00:05:10.625 --> 00:05:12.839
which we're going to pass in,

00:05:12.850 --> 00:05:16.040
and we're going to execute that.

00:05:20.259 --> 00:05:23.629
All right. So, now our create_trips_table,

00:05:23.629 --> 00:05:26.199
and it really shouldn't have the name trips in it anymore.

00:05:26.199 --> 00:05:28.060
So, we call this create_table.

00:05:28.060 --> 00:05:33.764
Our create_table task in our subDAG has been fully configured.

00:05:33.764 --> 00:05:38.474
Next, we need to look at our copy_trips_task and make this generic.

00:05:38.475 --> 00:05:41.030
So, the first thing we're going to do is remove

00:05:41.029 --> 00:05:43.699
this trips variable or trips name

00:05:43.699 --> 00:05:46.685
from our variable name because now we just want a generic copy task.

00:05:46.685 --> 00:05:48.439
Unlike in the previous example,

00:05:48.439 --> 00:05:54.475
we're going to use a formatting string and say, load_table from s3_to_redshift.

00:05:54.475 --> 00:05:57.470
Here, we're going to delete the trips_table because

00:05:57.470 --> 00:06:01.295
the table could be anything now that it's a subDAG that's reusable,

00:06:01.295 --> 00:06:07.439
and then we're going to replace the redshift_conn_id with redshift_conn_id.

00:06:07.990 --> 00:06:13.715
Again, these variables are coming from our function up here.

00:06:13.714 --> 00:06:19.799
Next, we need to fill in the s3 bucket and key and the aws_credentials_id.

00:06:21.170 --> 00:06:26.343
So here, we can no longer assume that the aws_credentials is aws_credentials,

00:06:26.343 --> 00:06:30.920
so we're going to use our variable aws_credentials_id.

00:06:30.920 --> 00:06:34.189
We're going to replace this specific bucket name with

00:06:34.189 --> 00:06:38.134
a variable name because the user may want to specify a different bucket.

00:06:38.134 --> 00:06:40.819
Finally, it will replace the key with

00:06:40.819 --> 00:06:44.990
a different key because the user may want to specify a different key.

00:06:44.990 --> 00:06:50.204
Now, at this point, we've defined our S3ToRedshiftOperator in a reusable fashion.

00:06:50.204 --> 00:06:53.974
Our subDAG is almost ready to go except we're missing one thing.

00:06:53.975 --> 00:06:57.140
We need to define ordering of our tasks.

00:06:57.139 --> 00:07:01.689
The create_task must occur before the copy_task.

00:07:01.689 --> 00:07:05.550
So, you can see here, I'm going to delete these TO DO's since we've done it.

00:07:05.550 --> 00:07:09.949
You can see here we have create_table, we have copy_task.

00:07:09.949 --> 00:07:17.159
So, we want to make sure that the create_table occurs before the copy_task.

00:07:17.160 --> 00:07:20.270
Now that we've done that, we can actually close this

00:07:20.269 --> 00:07:23.969
out because our subDAG should be properly configured.

00:07:25.569 --> 00:07:30.529
In here, we should be able to go in and now we can delete some of those code.

00:07:30.529 --> 00:07:36.179
We don't need to write this create_trips_table or copy_trips task anymore.

00:07:36.829 --> 00:07:43.189
Same with create_stations and copy_stations because we've parameterized or subDAGs above.

00:07:43.189 --> 00:07:45.889
So, now we only have check_trips,

00:07:45.889 --> 00:07:49.774
and check_stations, and our actual location_traffic_task.

00:07:49.774 --> 00:07:53.060
So, you can see down here that we still have to

00:07:53.060 --> 00:07:57.620
replace some of the usages of those create and copy_task.

00:07:57.620 --> 00:08:02.194
We're going to jump back up above and we're going to look at our SubDagOperator.

00:08:02.194 --> 00:08:05.170
So, we've instantiated the SubDagOperator,

00:08:05.170 --> 00:08:08.040
we've provided the subDAG function call,

00:08:08.040 --> 00:08:10.069
and we've properly parameterized

00:08:10.069 --> 00:08:14.029
the subDAG with all of the arguments that it would need to get going.

00:08:14.029 --> 00:08:20.369
So, we have a trip_subdag_task and we have a stations_subdag_task.

00:08:20.370 --> 00:08:25.300
So, at the bottom here,

00:08:25.300 --> 00:08:30.480
we're going to have a trip_subdag_task run before we actually

00:08:30.480 --> 00:08:35.279
run our location_traffic_task, excuse me,

00:08:35.279 --> 00:08:42.929
before we run our check_traffic_task or check_trips_task,

00:08:42.929 --> 00:08:48.159
and then we're going to run our stations_subdag_task

00:08:48.259 --> 00:08:52.179
before we run our check_stations_task.

00:08:52.789 --> 00:08:57.394
At this point, the create and copy steps can be removed.

00:08:57.394 --> 00:09:01.534
We can also remove the copy to check_stations dependencies.

00:09:01.534 --> 00:09:05.459
Now, we have a properly configured DAG.

00:09:05.710 --> 00:09:09.150
Let's see if Airflow loads the code.

00:09:09.700 --> 00:09:14.030
So, it looks like I miss to find something here.

00:09:14.029 --> 00:09:19.370
You can tell that if you've broken a DAG or your code isn't properly configured,

00:09:19.370 --> 00:09:21.590
Airflow will actually pop up a warning saying,

00:09:21.590 --> 00:09:23.220
"Hey, I couldn't parse your code."

00:09:23.220 --> 00:09:27.139
So, here it's saying the check_trips_task could not be found so it wasn't defined.

00:09:27.139 --> 00:09:30.365
So, let's see if we can see what's going on here.

00:09:30.365 --> 00:09:32.480
So, the first thing we notice is that,

00:09:32.480 --> 00:09:34.504
here, we have check_trips_task, right?

00:09:34.504 --> 00:09:36.085
I've used that variable name.

00:09:36.085 --> 00:09:39.360
But on line 55, it's actually defined as check_trips;

00:09:39.360 --> 00:09:41.399
same thing with check_stations.

00:09:41.399 --> 00:09:43.939
So, neither one of these variables is defined.

00:09:43.940 --> 00:09:48.755
So, I'm going to go to line 79, going to delete off the task,

00:09:48.754 --> 00:09:52.049
and so now we have properly named variables.

00:09:52.049 --> 00:09:56.194
Let's go and reload Airflow and see if it has picked up or changes.

00:09:56.195 --> 00:09:58.705
Now, when a DAG breaks,

00:09:58.705 --> 00:10:01.889
when you've made a mistake, it can take Airflow a few moments to pick up your changes.

00:10:01.889 --> 00:10:06.259
So, we're going to be patient and just give it a few moments here to pick up our changes.

00:10:06.259 --> 00:10:09.215
You can see when it fails to load,

00:10:09.215 --> 00:10:11.210
that Airflow actually, basically,

00:10:11.210 --> 00:10:12.230
black out the names,

00:10:12.230 --> 00:10:13.700
so you can't click on it, and it'll put

00:10:13.700 --> 00:10:16.610
those little information bubble here that you can hover over saying,

00:10:16.610 --> 00:10:19.230
"Hey, the DAG isn't available."

00:10:19.899 --> 00:10:23.424
So, we can now see that our error is gone,

00:10:23.424 --> 00:10:27.224
and we can see that lesson3.demo3 is now available again.

00:10:27.225 --> 00:10:30.180
Airflow is now able to correctly parse our DAG.

00:10:30.179 --> 00:10:31.500
So, we're going to look at the code.

00:10:31.500 --> 00:10:35.735
We're just going to verify that everything looks correct.

00:10:35.735 --> 00:10:39.134
We have our SubDagOperators, stations and trips.

00:10:39.134 --> 00:10:40.784
We have our two checks,

00:10:40.784 --> 00:10:46.219
a location_traffic_task, and we've reordered to use our subdag_task.

00:10:46.220 --> 00:10:48.970
So, let's go ahead and actually run this code.

00:10:48.970 --> 00:10:53.610
We go back to this menu, return on lesson3.demo3,

00:10:53.610 --> 00:11:00.620
going to click Play, and then we're going to open up a DAG and see that it works.

00:11:00.620 --> 00:11:03.889
So first, we're going to jump into our Graph View.

00:11:03.889 --> 00:11:06.500
So, you'll notice this looks a little different.

00:11:06.500 --> 00:11:09.440
We have a trips_subdag and the stations_subdag,

00:11:09.440 --> 00:11:11.510
and we'll see we don't get a lot of information.

00:11:11.509 --> 00:11:13.235
If I wanted to see more information,

00:11:13.235 --> 00:11:17.740
I could click on the trips_subdag and click Zoom into Sub DAG.

00:11:17.740 --> 00:11:19.924
This will show me more information.

00:11:19.924 --> 00:11:23.464
I'm going to wait for this to execute so we can get a little farther along.

00:11:23.465 --> 00:11:24.800
So, we can see this DAGs,

00:11:24.799 --> 00:11:30.279
these two subDAGs are both running now and they both completed.

00:11:30.279 --> 00:11:32.600
So, the two checks will know happen,

00:11:32.600 --> 00:11:35.210
and then the calculate_location_traffic task will happen.

00:11:35.210 --> 00:11:38.269
While they're doing that, let's take a look at our subDAG.

00:11:38.269 --> 00:11:40.429
So, before we jump in in the black menu here,

00:11:40.429 --> 00:11:43.819
you can see the operator type is SubDagOperator.

00:11:43.820 --> 00:11:48.415
If I click on this and then I go to Zoom into Sub DAG,

00:11:48.414 --> 00:11:51.799
I can actually see the steps that are part of my subDAG.

00:11:51.799 --> 00:11:54.949
So, notice up here, our menu looks a little different.

00:11:54.950 --> 00:12:00.430
SUBDAG: lesson3.demo3.trips_subdag.

00:12:00.429 --> 00:12:02.959
We can see that here we can actually see

00:12:02.960 --> 00:12:06.470
the PostgresOperators and the S3ToRedshiftOperator.

00:12:06.470 --> 00:12:08.195
Likewise, in the graph,

00:12:08.195 --> 00:12:11.825
we can see just the two tasks that are involved in our subDAG.

00:12:11.825 --> 00:12:16.860
I can even click in and see the logs just like I could in the past.

00:12:16.960 --> 00:12:19.535
So, let's return to their home menu,

00:12:19.534 --> 00:12:22.069
we'll go back to lesson3.demo3,

00:12:22.070 --> 00:12:26.220
and you can see there our DAG has now completed successfully.

