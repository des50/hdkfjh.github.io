{
  "data": {
    "lesson": {
      "id": 1128175,
      "key": "4d124bf6-49fe-4459-b609-8ddf2bd935d6",
      "title": "Data Pipelines",
      "semantic_type": "Lesson",
      "is_public": true,
      "version": "1.0.0",
      "locale": "en-us",
      "summary": null,
      "lesson_type": "Classroom",
      "display_workspace_project_only": null,
      "resources": {
        "files": [
          {
            "name": "Videos Zip File",
            "uri": "https://zips.udacity-data.com/4d124bf6-49fe-4459-b609-8ddf2bd935d6/1128175/1611251868365/Data+Pipelines+Videos.zip"
          },
          {
            "name": "Transcripts Zip File",
            "uri": "https://zips.udacity-data.com/4d124bf6-49fe-4459-b609-8ddf2bd935d6/1128175/1611251861739/Data+Pipelines+Subtitles.zip"
          }
        ],
        "google_plus_link": null,
        "career_resource_center_link": null,
        "coaching_appointments_link": null,
        "office_hours_link": null,
        "aws_provisioning_link": null
      },
      "project": null,
      "lab": null,
      "concepts": [
        {
          "id": 1112539,
          "key": "2fb765a2-4f87-4753-a01f-476f20d78a0e",
          "title": "Welcome",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "2fb765a2-4f87-4753-a01f-476f20d78a0e",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115309,
              "key": "a596ecc2-599d-48d1-a64e-b103b996bb63",
              "title": "Welcome",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "8X_TAOja-w4",
                "china_cdn_id": "8X_TAOja-w4.mp4"
              }
            }
          ]
        },
        {
          "id": 1112547,
          "key": "014b9542-83e8-455d-9085-e8a4accdd0ae",
          "title": "What is a Data Pipeline?",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "014b9542-83e8-455d-9085-e8a4accdd0ae",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115319,
              "key": "cc84ad9c-2743-461d-bd50-acaba57ea480",
              "title": "Definitions And Example Of Data Pipelines",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "8-WH7CUdmzc",
                "china_cdn_id": "8-WH7CUdmzc.mp4"
              }
            },
            {
              "id": 1115322,
              "key": "b0f87710-dca4-4acd-9d5f-23b7a791eb5f",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "## Checking Your Understanding of the Video",
              "instructor_notes": ""
            },
            {
              "id": 1115321,
              "key": "3ac94b0f-8703-441f-ae74-ad468dfb8b51",
              "title": "Data Pipeline",
              "semantic_type": "RadioQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "3ac94b0f-8703-441f-ae74-ad468dfb8b51",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "What is a data pipeline?",
                "answers": [
                  {
                    "id": "a1549735825920",
                    "text": "A visual way of displaying data to business users.",
                    "is_correct": false
                  },
                  {
                    "id": "a1549735835937",
                    "text": "An algorithm that classifies data.",
                    "is_correct": false
                  },
                  {
                    "id": "a1549735836710",
                    "text": "A series of steps in which data is processed.",
                    "is_correct": true
                  },
                  {
                    "id": "a1549735839584",
                    "text": "A type of database.",
                    "is_correct": false
                  }
                ]
              }
            },
            {
              "id": 1115320,
              "key": "cecac27d-6b70-4b2e-b78e-5f940862478b",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Defining New Terms\nThe video above includes references to a few terms that you may not be familiar with. Below are some definitions that you might find useful.\n\n#### Extract Transform Load (ETL) and Extract Load Transform (ELT): \n\n\"ETL is normally a continuous, ongoing process with a well-defined workflow. ETL first extracts data from homogeneous or heterogeneous data sources. Then, data is cleansed, enriched, transformed, and stored either back in the lake or in a data warehouse.\n\n\"ELT (Extract, Load, Transform) is a variant of ETL wherein the extracted data is first loaded into the target system. Transformations are performed after the data is loaded into the data warehouse. ELT typically works well when the target system is powerful enough to handle transformations. Analytical databases like Amazon Redshift and Google BigQ.\" <br>_Source:_ [Xplenty.com](https://www.xplenty.com/blog/etl-vs-elt/)\n\nThis [Quora post](https://www.quora.com/What-is-the-difference-between-the-ETL-and-ELT)  is also helpful if you'd like to read more. \n\n#### What is S3?\n \"Amazon S3 has a simple web services interface that you can use to store and retrieve any amount of data, at any time, from anywhere on the web. It gives any developer access to the same highly scalable, reliable, fast, inexpensive data storage infrastructure that Amazon uses to run its own global network of web sites.\"\n<br>_Source:_ [Amazon Web Services Documentation](https://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html).\n\n\nIf you want to learn more, start [here](https://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html).\n\n\n#### What is Kafka?\n\"Apache Kafka is an **open-source stream-processing software platform** developed by Linkedin and donated to the Apache Software Foundation, written in Scala and Java. The project aims to provide a unified, high-throughput, low-latency platform for handling real-time data feeds. Its storage layer is essentially a massively scalable pub/sub message queue designed as a distributed transaction log, making it highly valuable for enterprise infrastructures to process streaming data.\" <br>\n_Source:_ *Wikipedia*. \n\nIf you want to learn more, start [here](https://kafka.apache.org/intro).\n\n#### What is RedShift?\n\"Amazon Redshift is a fully managed, petabyte-scale data warehouse service in the cloud. You can start with just a few hundred gigabytes of data and scale to a petabyte or more... The first step to create a data warehouse is to launch a set of nodes, called an Amazon Redshift cluster. After you provision your cluster, you can upload your data set and then perform data analysis queries. Regardless of the size of the data set, Amazon Redshift offers fast query performance using the same SQL-based tools and business intelligence applications that you use today.\n\nIf you want to learn more, start [here](https://docs.aws.amazon.com/redshift/latest/mgmt/welcome.html).\n\nSo in other words, S3 is an example of the final data store where data might be loaded (e.g. ETL). While Redshift is an example of a data warehouse product, provided specifically by Amazon. ",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 1112530,
          "key": "31eb1050-f3c0-4754-b238-d04d3a98f1c6",
          "title": "Data Validation",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "31eb1050-f3c0-4754-b238-d04d3a98f1c6",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115284,
              "key": "f963f413-960b-491d-b82a-efee91038bf8",
              "title": "Data Validation",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "Y4N8CQbfExM",
                "china_cdn_id": "Y4N8CQbfExM.mp4"
              }
            },
            {
              "id": 1115285,
              "key": "4a6335f2-6f0c-4eac-a79b-d47ff5d44757",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "#### Data Validation\n\nData Validation is the process of ensuring that data is present, correct & meaningful. Ensuring the quality of your data through automated validation checks is a critical step in building data pipelines at any organization.\n\n\n",
              "instructor_notes": ""
            },
            {
              "id": 1115286,
              "key": "07116acb-633a-4a3b-ad67-22c82ca132f3",
              "title": "Data Validation",
              "semantic_type": "CheckboxQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "07116acb-633a-4a3b-ad67-22c82ca132f3",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "Which of the following are examples of data validation?",
                "answers": [
                  {
                    "id": "a1549735045591",
                    "text": "Ensuring that the number of rows in Redshift match the number of records in S3",
                    "is_correct": true
                  },
                  {
                    "id": "a1549735100090",
                    "text": "Ensuring that the number of rows in a table are greater than zero",
                    "is_correct": true
                  },
                  {
                    "id": "a1549735217438",
                    "text": "Ensuring that the output table matches the needs of the data consumer",
                    "is_correct": false
                  }
                ]
              }
            }
          ]
        },
        {
          "id": 1112536,
          "key": "565a36e5-76ab-496e-8ad9-e77806e8a842",
          "title": "DAGs and Data Pipelines",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "565a36e5-76ab-496e-8ad9-e77806e8a842",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115302,
              "key": "c5c3b717-59e3-48a0-86cd-0ceb29468a17",
              "title": "DAGs And Data Pipelines",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "YcahqfpcDeA",
                "china_cdn_id": "YcahqfpcDeA.mp4"
              }
            },
            {
              "id": 1115304,
              "key": "a463b821-9003-44ba-b82a-33b965a58d1b",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "#### Definitions\n* **Directed Acyclic Graphs (DAGs):** DAGs are a special subset of graphs in which the edges between nodes have a specific direction, and no cycles exist. When we say “no cycles exist” what we mean is the nodes cant create a path back to themselves.\n* **Nodes:** A step in the data pipeline process.\n* ** Edges:** The dependencies or relationships other between nodes.",
              "instructor_notes": ""
            },
            {
              "id": 1115305,
              "key": "b0f03f6e-0eec-4f4c-a6e1-68aa6e3ceb3b",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2019/February/5c5f5b00_capture/capture.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/b0f03f6e-0eec-4f4c-a6e1-68aa6e3ceb3b",
              "caption": "Diagram of a Directed Acyclic Graph",
              "alt": "",
              "width": 896,
              "height": 378,
              "instructor_notes": null
            },
            {
              "id": 1115303,
              "key": "d2727e2a-3873-4d77-8ffe-925993622a26",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "\n#### Common Questions\n**Are there real world cases where a data pipeline is not DAG? **\n\nIt is possible to model a data pipeline that is not a DAG, meaning that it contains a cycle within the process. However, the vast majority of use cases for data pipelines can be described as a directed acyclic graph (DAG). This makes the code more understandable and maintainable.\n\n**Can we have two different pipelines for the same data and can we merge them back together?**\n\nYes. It's not uncommon for a data pipeline to take the same dataset, perform two different processes to analyze the it, then merge the results of those two processes back together.",
              "instructor_notes": ""
            },
            {
              "id": 1115306,
              "key": "ac6a32c2-1ea4-4c9e-8027-5743ecfd2a48",
              "title": "Reflecting on Data Pipelines",
              "semantic_type": "ReflectAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "ac6a32c2-1ea4-4c9e-8027-5743ecfd2a48",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "title": null,
                "semantic_type": "TextQuestion",
                "evaluation_id": null,
                "text": "To help you solidify your knowledge, reflect on and write answers for the following questions.\n* What are data pipelines and how are they used? \n* What are a few examples of data pipeline?\n* What is data validation? \n* Why is data validation an important part of data pipelines?"
              },
              "answer": {
                "text": "Having a good understanding of these concepts will help you be a better data engineer!",
                "video": null
              }
            }
          ]
        },
        {
          "id": 1112518,
          "key": "12aa6258-6bb7-4973-b343-d764e7b4ba8e",
          "title": "Bikeshare DAG",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "12aa6258-6bb7-4973-b343-d764e7b4ba8e",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115263,
              "key": "4d86ce3d-43a4-4c96-a78f-9be5dfb1ea29",
              "title": "Bikeshare DAGs",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "-Z2I5i4bGS8",
                "china_cdn_id": "-Z2I5i4bGS8.mp4"
              }
            },
            {
              "id": 1115261,
              "key": "0ca0e679-bbfd-4dab-a29e-3e5d59b8d34a",
              "title": "Graphs",
              "semantic_type": "CheckboxQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "0ca0e679-bbfd-4dab-a29e-3e5d59b8d34a",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "What are the two components of ALL graphs? ",
                "answers": [
                  {
                    "id": "a1549753342224",
                    "text": "Cycle ",
                    "is_correct": false
                  },
                  {
                    "id": "a1549753347537",
                    "text": "Node",
                    "is_correct": true
                  },
                  {
                    "id": "a1549753348118",
                    "text": "Edge",
                    "is_correct": true
                  },
                  {
                    "id": "a1549753348612",
                    "text": "Direction",
                    "is_correct": false
                  }
                ]
              }
            },
            {
              "id": 1115262,
              "key": "97d9aac4-ce76-4c35-adc4-e53af75accea",
              "title": "DAGs",
              "semantic_type": "CheckboxQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "97d9aac4-ce76-4c35-adc4-e53af75accea",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "Which of the following are features which define a Directed Acyclic Graph?",
                "answers": [
                  {
                    "id": "a1549753486554",
                    "text": "Has Cycles ",
                    "is_correct": false
                  },
                  {
                    "id": "a1549753503533",
                    "text": "No Cycles",
                    "is_correct": true
                  },
                  {
                    "id": "a1549753510526",
                    "text": "Nodes may have more than one edge that connects to them ",
                    "is_correct": true
                  },
                  {
                    "id": "a1549753515436",
                    "text": "Edges between nodes imply a directed relationship ",
                    "is_correct": true
                  }
                ]
              }
            },
            {
              "id": 1115260,
              "key": "757c8c5d-5a2b-4d49-b00b-0128dd84210d",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2019/February/5c5f5dd3_dag-quiz/dag-quiz.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/757c8c5d-5a2b-4d49-b00b-0128dd84210d",
              "caption": "",
              "alt": "",
              "width": 1162,
              "height": 304,
              "instructor_notes": null
            },
            {
              "id": 1115264,
              "key": "9e5a4781-df57-450f-8238-cbb01c407a82",
              "title": "DAG Quiz",
              "semantic_type": "CheckboxQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "9e5a4781-df57-450f-8238-cbb01c407a82",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "Which graph(s) shown above are directed acyclic graphs (DAG)?",
                "answers": [
                  {
                    "id": "a1549753866988",
                    "text": "Graph 1",
                    "is_correct": false
                  },
                  {
                    "id": "a1549753917832",
                    "text": "Graph 2",
                    "is_correct": true
                  },
                  {
                    "id": "a1549753918254",
                    "text": "Graph 3",
                    "is_correct": false
                  }
                ]
              }
            }
          ]
        },
        {
          "id": 1112515,
          "key": "c23d5488-5116-43c2-9dcb-ca192ecc11c2",
          "title": "Introduction to Apache Airflow",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "c23d5488-5116-43c2-9dcb-ca192ecc11c2",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115249,
              "key": "8c2caf85-a537-47d2-a0b8-beb58c7d6ffc",
              "title": "Introduction To Apache Airflow",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "FNZmWBH2lTw",
                "china_cdn_id": "FNZmWBH2lTw.mp4"
              }
            },
            {
              "id": 1115250,
              "key": "15421ebe-62ba-47e4-bc00-20c1f0538239",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Apache Airflow\n\n\"Airflow is a platform to programmatically author, schedule and monitor workflows. Use airflow to author workflows as directed acyclic graphs (DAGs) of tasks. The airflow scheduler executes your tasks on an array of workers while following the specified dependencies. Rich command line utilities make performing complex surgeries on DAGs a snap. The rich user interface makes it easy to visualize pipelines running in production, monitor progress, and troubleshoot issues when needed. When workflows are defined as code, they become more maintainable, versionable, testable, and collaborative.\" \n\nIf you'd like to learn more, start [here](https://airflow.apache.org/).",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 1112531,
          "key": "c1e778c5-1125-47c4-a13f-7d80a0662112",
          "title": "Demo 1: Airflow DAGs",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "c1e778c5-1125-47c4-a13f-7d80a0662112",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115288,
              "key": "47856ce3-022e-4957-bce8-3a6c6ff4a42f",
              "title": "07  Hello World DAG  Demo 1 V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "vtV2qQk4Sc0",
                "china_cdn_id": "vtV2qQk4Sc0.mp4"
              }
            },
            {
              "id": 1115287,
              "key": "08a066df-707d-40f7-b25c-4b0d29f198d1",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Tips for Using Airflow's Web Server\n* Use Google Chrome to view the Web Server. Airflow sometimes has issues rendering correctly in Firefox or other browers.\n* Make sure you toggle the DAG to `On` before you try an run it. Otherwise you'll see your DAG running, but it won't ever finish.\n",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 1112532,
          "key": "c2c9f608-3ff5-47ba-bf87-c5a261a952f4",
          "title": "Workspace Instructions",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "c2c9f608-3ff5-47ba-bf87-c5a261a952f4",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115289,
              "key": "2e3300c8-ee52-4768-9f69-717371030e9d",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "## Workspace Instructions\n\nBefore you start on your first exercise, please note the following instruction.\n\n1. After you have updated the DAG, you will need to run `/opt/airflow/start.sh` command to start the Airflow webserver. See the screenshot below for the Exercise 1 Workspace.",
              "instructor_notes": ""
            },
            {
              "id": 1115290,
              "key": "3308d969-852f-4bcc-8679-88fe5f9e5db3",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2019/April/5ca5188c_opt-airflow-image2/opt-airflow-image2.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/3308d969-852f-4bcc-8679-88fe5f9e5db3",
              "caption": "",
              "alt": "",
              "width": 1723,
              "height": 813,
              "instructor_notes": null
            },
            {
              "id": 1115291,
              "key": "ae111e95-c20f-4028-91b6-823f95c8d272",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "2. Wait for the Airflow web server to be ready (see screenshot below).",
              "instructor_notes": ""
            },
            {
              "id": 1115292,
              "key": "b7fc2b65-310f-4020-86d3-00424c4e3c19",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2019/April/5ca5190c_opt-airflow-image3/opt-airflow-image3.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/b7fc2b65-310f-4020-86d3-00424c4e3c19",
              "caption": "",
              "alt": "",
              "width": 1723,
              "height": 809,
              "instructor_notes": null
            },
            {
              "id": 1115293,
              "key": "00c482ef-cd25-4813-9f15-8f8ccbaef37d",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "3. Access the Airflow UI by clicking on the blue \"Access Airflow\" button.\n\nThis should be able to access the Airflow UI without any delay.\n\n__Please note:__ Because the files located in the s3 bucket 'udacity-dend' are very large, Airflow can take up to 10 minutes to make the connection.",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 1112543,
          "key": "318b2767-f89e-4e92-83b5-07fd0a9afc35",
          "title": "Exercise 1: Airflow DAGs",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "318b2767-f89e-4e92-83b5-07fd0a9afc35",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115314,
              "key": "3ce4af18-1637-42c0-96e0-b490beaf7aeb",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "r766469c817261xREACTblube3pv",
              "pool_id": "airflow",
              "view_id": "react-gh7p3",
              "gpu_capable": false,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": {
                      "id": "mldatasets",
                      "paths": [
                        {
                          "src": "/",
                          "dest": "/data/"
                        }
                      ],
                      "mountWarnUntil": 0
                    },
                    "port": 3000,
                    "ports": [],
                    "userCode": "",
                    "openFiles": [
                      "/home/workspace/airflow/dags/lesson1_exercises/exercise1.py"
                    ],
                    "showFiles": true,
                    "allowClose": true,
                    "allowSubmit": false,
                    "terminalTitle": "BASH",
                    "actionButtonText": "Access Airflow",
                    "openTerminalOnStartup": true
                  },
                  "kind": "react"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        },
        {
          "id": 1112522,
          "key": "9727836c-4ad1-4246-8bdb-5645973030ff",
          "title": "Solution 1: Airflow DAGs",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "9727836c-4ad1-4246-8bdb-5645973030ff",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115270,
              "key": "f1f96be1-25a8-4607-ab88-87c66929f280",
              "title": "Exercise 1  Solution V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "oLZuImgbugw",
                "china_cdn_id": "oLZuImgbugw.mp4"
              }
            },
            {
              "id": 1115271,
              "key": "178e3785-beba-4937-b467-d17832b13713",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "__Callables__ can also be thought of as passing functions that can be included as arguments to other functions.  Examples of callables are map, reduce, filter. This is a pretty powerful feature of python you can explore more using the resources below. Callables are examples of functional programming that is introduced in an earlier lesson.\n\nHere is the link to the [Python documentation on callables](https://docs.python.org/3.4/library/functools.html).",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 1112517,
          "key": "7da8bf38-8388-476b-a440-6f03b6ff71e8",
          "title": "How Airflow Works",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "7da8bf38-8388-476b-a440-6f03b6ff71e8",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115254,
              "key": "0155e7a7-29ba-4fe8-9dcc-07e814840c4d",
              "title": "How Airflow Works",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "vltaMg-mC4I",
                "china_cdn_id": "vltaMg-mC4I.mp4"
              }
            },
            {
              "id": 1115255,
              "key": "e8eaf265-58f4-493b-8ee0-e60a6571e5d0",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Note: Ben refers to \"Coco\" in the video. He's referring to using an Airflow Workspace within the Udacity classroom.",
              "instructor_notes": ""
            },
            {
              "id": 1115257,
              "key": "c1b43dc7-1eeb-4a7c-be7b-90646e60d1ed",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### <center> Components of Airflow \n",
              "instructor_notes": ""
            },
            {
              "id": 1115258,
              "key": "d614a9a8-66d4-4b80-88be-9f8b5495ce03",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2019/February/5c5f6105_airflow-diagram/airflow-diagram.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/d614a9a8-66d4-4b80-88be-9f8b5495ce03",
              "caption": "",
              "alt": "",
              "width": 819,
              "height": 333,
              "instructor_notes": null
            },
            {
              "id": 1115252,
              "key": "8fe25abf-7ed0-4cde-a698-1e140f84ec48",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "* **Scheduler** orchestrates the execution of jobs on a trigger or schedule. The Scheduler chooses how to prioritize the running and execution of tasks within the system. You can learn more about the Scheduler from the official [Apache Airflow documentation](https://airflow.apache.org/scheduler.html).\n* **Work Queue** is used by the scheduler in most Airflow installations to deliver tasks that need to be run to the **Workers**. \n* **Worker** processes execute the operations defined in each DAG. In most Airflow installations, workers pull from the **work queue** when it is ready to process a task. When the worker completes the execution of the task, it will attempt to process more work from the **work queue** until there is no further work remaining. When work in the queue arrives, the worker will begin to process it.\n* **Database** saves credentials, connections, history, and configuration. The database, often referred to as the _metadata database_, also stores the state of all tasks in the system. Airflow components interact with the database with the Python ORM, [SQLAlchemy](https://www.sqlalchemy.org/).\n* **Web Interface** provides a control dashboard for users and maintainers. Throughout this course you will see how the web interface allows users to perform tasks such as stopping and starting DAGs, retrying failed tasks, configuring credentials, The web interface is built using the [Flask web-development microframework](http://flask.pocoo.org/).\n",
              "instructor_notes": ""
            },
            {
              "id": 1115259,
              "key": "2499abb3-dafd-417c-90a6-1fb447fc7505",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### <center>How Airflow Works",
              "instructor_notes": ""
            },
            {
              "id": 1115256,
              "key": "4be59871-eec1-4786-b1d6-1907adde3bdf",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2019/February/5c5f8e1d_how-airflow-works/how-airflow-works.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/4be59871-eec1-4786-b1d6-1907adde3bdf",
              "caption": "",
              "alt": "",
              "width": 1396,
              "height": 649,
              "instructor_notes": null
            },
            {
              "id": 1115253,
              "key": "2a33f1b9-31e9-434a-b839-474a92844bbe",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Order of Operations For an Airflow DAG\n* The Airflow Scheduler starts DAGs based on time or external triggers.\n* Once a DAG is started, the Scheduler looks at the steps within the DAG and determines which steps can run by looking at their dependencies.\n* The Scheduler places runnable steps in the queue.\n* Workers pick up those tasks and run them. \n* Once the worker has finished running the step, the final status of the task is recorded and additional tasks are placed by the scheduler until all tasks are complete.\n* Once all tasks have been completed, the DAG is complete. \n\n",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 1112533,
          "key": "c13888fb-736e-4e8b-91f4-965d4340f274",
          "title": "Airflow Runtime Architecture",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "c13888fb-736e-4e8b-91f4-965d4340f274",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115294,
              "key": "080e5cc1-299d-413d-b820-9c88532386c5",
              "title": "Airflow components",
              "semantic_type": "CheckboxQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "080e5cc1-299d-413d-b820-9c88532386c5",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "What are the five components of Airflow’s architecture?",
                "answers": [
                  {
                    "id": "a1549756162883",
                    "text": "Scheduler",
                    "is_correct": true
                  },
                  {
                    "id": "a1549756192872",
                    "text": "Data Warehouse",
                    "is_correct": false
                  },
                  {
                    "id": "a1549756193327",
                    "text": "Workers",
                    "is_correct": true
                  },
                  {
                    "id": "a1549756193806",
                    "text": "UI/Web Server",
                    "is_correct": true
                  },
                  {
                    "id": "a1549756194246",
                    "text": "Queue",
                    "is_correct": true
                  },
                  {
                    "id": "a1549756194661",
                    "text": "Streaming Server",
                    "is_correct": false
                  },
                  {
                    "id": "a1549756236111",
                    "text": "Database",
                    "is_correct": true
                  }
                ]
              }
            },
            {
              "id": 1115297,
              "key": "7250ebd4-59ed-4cd2-90c7-2dfbfb10202b",
              "title": "Airflow UI",
              "semantic_type": "RadioQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "7250ebd4-59ed-4cd2-90c7-2dfbfb10202b",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "What does the Airflow UI do?",
                "answers": [
                  {
                    "id": "a1549755177203",
                    "text": "Allow the user to construct data pipelines graphically in the UI",
                    "is_correct": false
                  },
                  {
                    "id": "a1549755178460",
                    "text": "Provides a control interface for users and maintainers",
                    "is_correct": true
                  },
                  {
                    "id": "a1549755178661",
                    "text": "Allows the user to write queries against databases",
                    "is_correct": false
                  },
                  {
                    "id": "a1549755179196",
                    "text": "Runs and records the outcome of individual pipeline tasks ",
                    "is_correct": false
                  }
                ]
              }
            },
            {
              "id": 1115296,
              "key": "2dc95d84-5802-4c86-a2fc-49f614a93ddf",
              "title": "Scheduler",
              "semantic_type": "RadioQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "2dc95d84-5802-4c86-a2fc-49f614a93ddf",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "What does the Airflow Scheduler do?",
                "answers": [
                  {
                    "id": "a1549755610504",
                    "text": "Runs and records the outcome of individual pipeline tasks",
                    "is_correct": false
                  },
                  {
                    "id": "a1549755612999",
                    "text": "Provides a control interface for users and maintainers",
                    "is_correct": false
                  },
                  {
                    "id": "a1549755613446",
                    "text": "Sends emails on a scheduled basis",
                    "is_correct": false
                  },
                  {
                    "id": "a1549755613926",
                    "text": "Starts DAGs based on triggers or schedules and moves them towards completion",
                    "is_correct": true
                  }
                ]
              }
            },
            {
              "id": 1115295,
              "key": "df9b7391-b20d-4bd0-9965-aedda1f9f976",
              "title": "Workers",
              "semantic_type": "RadioQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "df9b7391-b20d-4bd0-9965-aedda1f9f976",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "What do the Airflow Workers do?",
                "answers": [
                  {
                    "id": "a1549755723721",
                    "text": "Runs and records the outcome of individual pipeline tasks",
                    "is_correct": true
                  },
                  {
                    "id": "a1549755725990",
                    "text": "Provides a control interface for users and maintainers",
                    "is_correct": false
                  },
                  {
                    "id": "a1549755726525",
                    "text": "Sends emails on a scheduled basis",
                    "is_correct": false
                  },
                  {
                    "id": "a1549755726910",
                    "text": "Starts DAGs based on triggers or schedules and moves them towards completion",
                    "is_correct": false
                  }
                ]
              }
            }
          ]
        },
        {
          "id": 1112545,
          "key": "230fa0fd-6ebd-4bd9-b7a2-3542552414c7",
          "title": "Building a Data Pipeline",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "230fa0fd-6ebd-4bd9-b7a2-3542552414c7",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115317,
              "key": "b888b1d7-d056-4118-895f-e2fef3e9cde0",
              "title": "Building A Data Pipeline",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "vW1A4cTjdks",
                "china_cdn_id": "vW1A4cTjdks.mp4"
              }
            },
            {
              "id": 1115316,
              "key": "358e9cde-d5d9-4b49-b92a-74cb6cff4c81",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Creating a DAG\n\nCreating a DAG is easy. Give it a name, a description, a start date, and an interval.\n\n```\nfrom airflow import DAG\n\n\ndivvy_dag = DAG(\n\t'divvy',\n\tdescription='Analyzes Divvy Bikeshare Data',\n\tstart_date=datetime(2019, 2, 4),\n\tschedule_interval='@daily')\n```\n\n### Creating Operators to Perform Tasks\n\n**Operators** define the atomic steps of work that make up a DAG. Instantiated operators are referred to as **Tasks**.\n\n```\nfrom airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\n\ndef hello_world():\n    print(“Hello World”)\n\ndivvy_dag = DAG(...)\ntask = PythonOperator(\n    task_id=’hello_world’,\n    python_callable=hello_world,\n    dag=divvy_dag)\n```\n\n### Schedules\n\n**Schedules** are optional, and may be defined with cron strings or Airflow Presets. Airflow provides the following presets:\n\n* `@once` - Run a DAG once and then never again\n* `@hourly` - Run the DAG every hour\n* `@daily` - Run the DAG every day\n* `@weekly` - Run the DAG every week\n* `@monthly` - Run the DAG every month\n* `@yearly`- Run the DAG every year\n* `None` - Only run the DAG when the user initiates it\n\n**Start Date:** If your start date is in the past, Airflow will run your DAG as many times as there are schedule intervals between that start date and the current date. \n\n**End Date:** Unless you specify an optional end date, Airflow will continue to run your DAGs until you disable or delete the DAG.\n",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 1112525,
          "key": "3b2e4121-87fc-464d-a288-9de8b7691763",
          "title": "Demo 2: Run the Schedules",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "3b2e4121-87fc-464d-a288-9de8b7691763",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115275,
              "key": "85ccf547-cc6c-413d-abb0-151904791f84",
              "title": "Configuring & Scheduling - Demo 2-",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "FyJEXY8h3YE",
                "china_cdn_id": "FyJEXY8h3YE.mp4"
              }
            }
          ]
        },
        {
          "id": 1112537,
          "key": "cd868d0e-d8f4-47b4-9334-81819bbeaacd",
          "title": "Exercise 2: Run the Schedules",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "cd868d0e-d8f4-47b4-9334-81819bbeaacd",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115307,
              "key": "d9b98d9c-48e8-4bd8-86b7-13d7970eda13",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "r766469c817261xREACTblube3pv",
              "pool_id": "airflow",
              "view_id": "react-v4e45",
              "gpu_capable": false,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": {
                      "id": "mldatasets",
                      "paths": [
                        {
                          "src": "/",
                          "dest": "/data/"
                        }
                      ],
                      "mountWarnUntil": 0
                    },
                    "port": 3000,
                    "ports": [],
                    "userCode": "",
                    "openFiles": [
                      "/home/workspace/airflow/dags/lesson1_exercises/exercise2.py"
                    ],
                    "showFiles": true,
                    "allowClose": true,
                    "allowSubmit": false,
                    "terminalTitle": "BASH",
                    "actionButtonText": "Access Airflow",
                    "openTerminalOnStartup": true
                  },
                  "kind": "react"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        },
        {
          "id": 1112523,
          "key": "7a158163-348b-45c9-9387-b41e0511e974",
          "title": "Solution 2: Run the Schedules",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "7a158163-348b-45c9-9387-b41e0511e974",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115272,
              "key": "ab79cbc3-1e25-4054-a2cd-63f63f8eae3c",
              "title": "Exercise 2  Solution V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "nW6Bnrlw3Ys",
                "china_cdn_id": "nW6Bnrlw3Ys.mp4"
              }
            }
          ]
        },
        {
          "id": 1112519,
          "key": "2e7ee2e9-831f-4171-9c12-ff793adf9d7a",
          "title": "Operators and Tasks",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "2e7ee2e9-831f-4171-9c12-ff793adf9d7a",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115266,
              "key": "c36f992d-4171-41a2-a4d3-810a900a51f9",
              "title": "Monitor And Debug Pipeline Jobs",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "IJKsUQWz_Vo",
                "china_cdn_id": "IJKsUQWz_Vo.mp4"
              }
            },
            {
              "id": 1115265,
              "key": "c1d23de8-ffac-4a3d-afea-8709624ccab5",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Operators\n\nOperators define the atomic steps of work that make up a DAG. Airflow comes with many Operators that can perform common operations. Here are a handful of common ones:\n* `PythonOperator`\n* `PostgresOperator`\n* `RedshiftToS3Operator`\n* `S3ToRedshiftOperator`\n* `BashOperator`\n* `SimpleHttpOperator`\n* `Sensor`\n\n### Task Dependencies \n\nIn Airflow DAGs:\n* Nodes = Tasks\n* Edges = Ordering and dependencies between tasks\n\nTask dependencies can be described programmatically in Airflow using `>>` and `<<`\n* a `>>` b means a comes before b\n* a `<<` b means a comes after b\n\n```\nhello_world_task = PythonOperator(task_id=’hello_world’, ...)\ngoodbye_world_task = PythonOperator(task_id=’goodbye_world’, ...)\n...\n# Use >> to denote that goodbye_world_task depends on hello_world_task\nhello_world_task >> goodbye_world_task\n```\n\nTasks dependencies can also be set with “set_downstream” and “set_upstream”\n* `a.set_downstream(b)` means a comes before b\n* `a.set_upstream(b)` means a comes after b\n\n```\nhello_world_task = PythonOperator(task_id=’hello_world’, ...)\ngoodbye_world_task = PythonOperator(task_id=’goodbye_world’, ...)\n...\nhello_world_task.set_downstream(goodbye_world_task)\n```",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 1112534,
          "key": "265aaa9c-1119-4e49-b29d-17386f82fd58",
          "title": "Demo 3: Task Dependencies",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "265aaa9c-1119-4e49-b29d-17386f82fd58",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115298,
              "key": "c458ed6f-8132-4b6b-bca4-c33738baf66b",
              "title": "Operators And Tasks - Demo 3",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "gCnP3MqwEic",
                "china_cdn_id": "gCnP3MqwEic.mp4"
              }
            },
            {
              "id": 1115299,
              "key": "6b5ac86d-38a9-4630-b474-bb6a4b77071d",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "_Error:_ At timestamp 2.53, the instructor incorrectly said out loud \"hello_world_task depends on working_dir_task\". The correct audio should be \"hello_world_task needs to be run before working_dir_task.\"",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 1112541,
          "key": "bc62aca9-039b-429c-8cf9-fef62d666053",
          "title": "Exercise 3: Task Dependencies ",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "bc62aca9-039b-429c-8cf9-fef62d666053",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115312,
              "key": "e609aa8f-3848-4a52-87f1-5b1eaff4b526",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "r766469c817261xREACTblube3pv",
              "pool_id": "airflow",
              "view_id": "react-yn8m4",
              "gpu_capable": false,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": {
                      "id": "mldatasets",
                      "paths": [
                        {
                          "src": "/",
                          "dest": "/data/"
                        }
                      ],
                      "mountWarnUntil": 0
                    },
                    "port": 3000,
                    "ports": [],
                    "userCode": "",
                    "openFiles": [
                      "/home/workspace/airflow/dags/lesson1_exercises/exercise3.py"
                    ],
                    "showFiles": true,
                    "allowClose": true,
                    "allowSubmit": false,
                    "terminalTitle": "BASH",
                    "actionButtonText": "Access Airflow",
                    "openTerminalOnStartup": true
                  },
                  "kind": "react"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        },
        {
          "id": 1112524,
          "key": "c0e64e21-0ffa-48e9-bbaa-15597e6494e4",
          "title": "Solution: Task Dependencies",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "c0e64e21-0ffa-48e9-bbaa-15597e6494e4",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115273,
              "key": "81d1b90e-c1e4-4039-b6f8-02f1a9de7067",
              "title": "Exercise 3  Solution V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "g7WPth-PbJc",
                "china_cdn_id": "g7WPth-PbJc.mp4"
              }
            },
            {
              "id": 1115274,
              "key": "7ccd3cd8-9301-4da8-9a3a-f37bfc02fe26",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "r766469c817261xREACTblube3pv",
              "pool_id": "airflow",
              "view_id": "react-6qfw0",
              "gpu_capable": false,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": {
                      "id": "mldatasets",
                      "paths": [
                        {
                          "src": "/",
                          "dest": "/data/"
                        }
                      ],
                      "mountWarnUntil": 0
                    },
                    "port": 3000,
                    "ports": [],
                    "userCode": "",
                    "openFiles": [
                      "/home/workspace/airflow/dags/lesson1_solutions/solution3.py"
                    ],
                    "showFiles": true,
                    "allowClose": true,
                    "allowSubmit": false,
                    "terminalTitle": "BASH",
                    "actionButtonText": "Access Airflow",
                    "openTerminalOnStartup": true
                  },
                  "kind": "react"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        },
        {
          "id": 1112521,
          "key": "e11ff6cd-2142-488e-8d80-087ff3e4020c",
          "title": "Airflow Hooks",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "e11ff6cd-2142-488e-8d80-087ff3e4020c",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115268,
              "key": "4733363f-50a0-4b1c-ae14-b0e2e6f12cd9",
              "title": "13-1 - Building Pipelines In Airflow - Hooks And Connections - Demo 4",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "2Vkh9rfh6vE",
                "china_cdn_id": "2Vkh9rfh6vE.mp4"
              }
            },
            {
              "id": 1115269,
              "key": "fbaf1c6e-481e-4d78-9799-c91ac525dae1",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Connection via Airflow Hooks\n\nConnections can be accessed in code via hooks. Hooks provide a reusable interface to external systems and databases. With hooks, you don’t have to worry about how and where to store these connection strings and secrets in your code.\n\n```\nfrom airflow import DAG\nfrom airflow.hooks.postgres_hook import PostgresHook\nfrom airflow.operators.python_operator import PythonOperator\n\ndef load():\n# Create a PostgresHook option using the `demo` connection\n    db_hook = PostgresHook(‘demo’)\n    df = db_hook.get_pandas_df('SELECT * FROM rides')\n    print(f'Successfully used PostgresHook to return {len(df)} records')\n\nload_task = PythonOperator(task_id=’load’, python_callable=hello_world, ...)\n```\n\nAirflow comes with many Hooks that can integrate with common systems. Here are a few common ones: \n* `HttpHook`\n* `PostgresHook` (works with RedShift)\n* `MySqlHook`\n* `SlackHook`\n* `PrestoHook`\n\n",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 1112535,
          "key": "b33516be-e5c3-4198-baef-2cd0e6a97a83",
          "title": "Demo 4: Connections and Hooks",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "b33516be-e5c3-4198-baef-2cd0e6a97a83",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115300,
              "key": "fa1afe96-7ee2-4b94-8bd9-10f4e2d03c23",
              "title": "Demo4 Connections Hooks",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "VbBALfhw_v8",
                "china_cdn_id": "VbBALfhw_v8.mp4"
              }
            },
            {
              "id": 1115301,
              "key": "0f004a3b-37eb-4f62-a01b-b2b20908e566",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Correction to Video###\nThe instructions in the video are incorrect about the S3 bucket.\n\nYou should create two Airflow variables in the UI:\n- s3_bucket: udacity-dend\n- s3_prefix: data-pipelines\n\nUsing this S3 prefix filters the returned S3 keys, so the number of objects displayed for that bucket will be greatly reduced, and you'll avoid the UI freezing.",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 1112542,
          "key": "8414c9c8-c337-4428-aed9-000fc67d69a8",
          "title": "Exercise 4: Connections and Hooks",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "8414c9c8-c337-4428-aed9-000fc67d69a8",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115313,
              "key": "1016e88f-bd2d-4ff8-876a-9b39d187aec0",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "r766469c817261xREACTblube3pv",
              "pool_id": "airflow",
              "view_id": "react-leoic",
              "gpu_capable": false,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": {
                      "id": "mldatasets",
                      "paths": [
                        {
                          "src": "/",
                          "dest": "/data/"
                        }
                      ],
                      "mountWarnUntil": 0
                    },
                    "port": 3000,
                    "ports": [],
                    "userCode": "",
                    "openFiles": [
                      "/home/workspace/airflow/dags/lesson1_exercises/exercise4.py"
                    ],
                    "showFiles": true,
                    "allowClose": true,
                    "allowSubmit": false,
                    "terminalTitle": "BASH",
                    "actionButtonText": "Access Airflow",
                    "openTerminalOnStartup": true
                  },
                  "kind": "react"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        },
        {
          "id": 1112526,
          "key": "d9cef0af-f4b8-43e1-ba54-be48c320fa2a",
          "title": "Solution 4: Connections and Hooks",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "d9cef0af-f4b8-43e1-ba54-be48c320fa2a",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115276,
              "key": "69c9a9f0-5912-473f-a04c-4b0bede41a97",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Solution 4: Connections and Hooks\n\nBelow is the solution for Exercise 4: Connections and Hooks.\n\n```\nimport datetime\nimport logging\n\nfrom airflow import DAG\nfrom airflow.models import Variable\nfrom airflow.operators.python_operator import PythonOperator\nfrom airflow.hooks.S3_hook import S3Hook\n\n\ndef list_keys():\n    hook = S3Hook(aws_conn_id='aws_credentials')\n    bucket = Variable.get('s3_bucket')\n    prefix = Variable.get('s3_prefix')\n    logging.info(f\"Listing Keys from {bucket}/{prefix}\")\n    keys = hook.list_keys(bucket, prefix=prefix)\n    for key in keys:\n        logging.info(f\"- s3://{bucket}/{key}\")\n\n\ndag = DAG(\n        'lesson1.exercise4',\n        start_date=datetime.datetime.now())\n\nlist_task = PythonOperator(\n    task_id=\"list_keys\",\n    python_callable=list_keys,\n    dag=dag\n)\n```",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 1112527,
          "key": "a7ef0618-7882-42e4-8951-e02917b2e831",
          "title": "Demo 5: Context and Templating",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "a7ef0618-7882-42e4-8951-e02917b2e831",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115279,
              "key": "32644574-c8a1-416f-94da-0388e1b0a26a",
              "title": "Templating With Context Variables - Demo 5",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "fIWLBsGjW2c",
                "china_cdn_id": "fIWLBsGjW2c.mp4"
              }
            },
            {
              "id": 1115280,
              "key": "45e84bf5-9be1-4ee3-9f8c-fb517e30ceb9",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "_Correction:_  At timestamp 0.05 in the video above, the ending square bracket is missing. It should be <br>```python\nprint(f\"Hello {kwargs['execution_date']}\")\n```",
              "instructor_notes": ""
            },
            {
              "id": 1115278,
              "key": "c5a25696-fb2c-4b00-82c2-0bcef5c816f2",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "[Here](https://airflow.apache.org/docs/apache-airflow/stable/macros-ref.html) is the Apache Airflow documentation on __context variables__ that can be included as kwargs.\n\nHere is a link to a [blog post](https://blog.godatadriven.com/zen-of-python-and-apache-airflow) that also discusses this topic.\n",
              "instructor_notes": ""
            },
            {
              "id": 1115277,
              "key": "601ea48a-8511-450e-83c4-a68474aa64df",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "### Runtime Variables\n\nAirflow leverages templating to allow users to “fill in the blank” with important runtime variables for tasks.\n\n```\nfrom airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\n\ndef hello_date(*args, **kwargs):\n    print(f“Hello {kwargs[‘execution_date’]}”)\n\ndivvy_dag = DAG(...)\ntask = PythonOperator(\n    task_id=’hello_date’,\n    python_callable=hello_date,\n    provide_context=True,\n    dag=divvy_dag)\n```",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 1112516,
          "key": "e5461e76-3c50-4282-b260-1fa9a9c5dce9",
          "title": "Exercise 5: Context and Templating",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "e5461e76-3c50-4282-b260-1fa9a9c5dce9",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115251,
              "key": "54e04424-159b-48a2-9cdf-a34d0738da59",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "r766469c817261xREACTblube3pv",
              "pool_id": "airflow",
              "view_id": "react-if1zf",
              "gpu_capable": false,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": {
                      "id": "mldatasets",
                      "paths": [
                        {
                          "src": "/",
                          "dest": "/data/"
                        }
                      ],
                      "mountWarnUntil": 0
                    },
                    "port": 3000,
                    "ports": [],
                    "userCode": "",
                    "openFiles": [
                      "/home/workspace/airflow/dags/lesson1_exercises/exercise5.py"
                    ],
                    "showFiles": true,
                    "allowClose": true,
                    "allowSubmit": false,
                    "terminalTitle": "BASH",
                    "actionButtonText": "Access Airflow",
                    "openTerminalOnStartup": true
                  },
                  "kind": "react"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        },
        {
          "id": 1112528,
          "key": "921aff85-93db-45ec-8096-d641a743a2b2",
          "title": "Solution 5: Context and Templating",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "921aff85-93db-45ec-8096-d641a743a2b2",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115281,
              "key": "30a36eeb-e2f3-4b4c-8cc4-510da2f1371d",
              "title": "Exercise 5  Solution V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "Fe22Ws_OCBI",
                "china_cdn_id": "Fe22Ws_OCBI.mp4"
              }
            },
            {
              "id": 1115282,
              "key": "1dbc8b71-5d62-43b7-8c1e-d49fd474c99a",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "The link for the Airflow documentation on context variables has changed since the video was created. Here is the new link: [https://airflow.apache.org/macros.html](https://airflow.apache.org/macros.html)",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 1112540,
          "key": "65a9767c-1940-4365-a401-6e16272b4a18",
          "title": "Quiz: Review of Pipeline Components",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "65a9767c-1940-4365-a401-6e16272b4a18",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115311,
              "key": "6d4b648c-44f3-4218-98e7-60d136806b3a",
              "title": "Pipeline Components",
              "semantic_type": "MatchingQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "6d4b648c-44f3-4218-98e7-60d136806b3a",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "complex_prompt": {
                  "text": "Match the following definitions to the the component they describe."
                },
                "concepts_label": "Definition",
                "answers_label": "Component",
                "concepts": [
                  {
                    "text": "A collection of nodes and edges that describe the order of operations for a data pipeline ",
                    "correct_answer": {
                      "id": "a1549761951971",
                      "text": "DAG"
                    }
                  },
                  {
                    "text": "An instantiated step in a pipeline fully parameterized for execution",
                    "correct_answer": {
                      "id": "a1549761970612",
                      "text": "Task"
                    }
                  },
                  {
                    "text": "A reusable connection to an external database or system",
                    "correct_answer": {
                      "id": "a1549761980326",
                      "text": "Hook"
                    }
                  },
                  {
                    "text": "An abstract building block that can be configured to perform some work",
                    "correct_answer": {
                      "id": "a1549761991261",
                      "text": "Operator"
                    }
                  }
                ],
                "answers": [
                  {
                    "id": "a1549762067312",
                    "text": "Database"
                  },
                  {
                    "id": "a1549761980326",
                    "text": "Hook"
                  },
                  {
                    "id": "a1549761970612",
                    "text": "Task"
                  },
                  {
                    "id": "a1549761983437",
                    "text": "Scheduler"
                  },
                  {
                    "id": "a1549761951971",
                    "text": "DAG"
                  },
                  {
                    "id": "a1549762096575",
                    "text": "Database"
                  },
                  {
                    "id": "a1549762075862",
                    "text": "Queue"
                  },
                  {
                    "id": "a1549761991261",
                    "text": "Operator"
                  }
                ]
              }
            },
            {
              "id": 1115310,
              "key": "b1f9f3ec-82f6-4224-8682-16d8438c2cdf",
              "title": "Dependencies",
              "semantic_type": "RadioQuizAtom",
              "is_public": true,
              "instructor_notes": null,
              "user_state": {
                "node_key": "b1f9f3ec-82f6-4224-8682-16d8438c2cdf",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "question": {
                "prompt": "Which of the following constructs a DAG that runs task “B”, then “C”, then “A”?\n",
                "answers": [
                  {
                    "id": "a1549762363937",
                    "text": "A >> C >> B",
                    "is_correct": false
                  },
                  {
                    "id": "a1549762391062",
                    "text": "B >> C >> A ",
                    "is_correct": true
                  },
                  {
                    "id": "a1549762391421",
                    "text": "C >> A >> B ",
                    "is_correct": false
                  },
                  {
                    "id": "a1549762398958",
                    "text": "B >> A >> C ",
                    "is_correct": false
                  }
                ]
              }
            }
          ]
        },
        {
          "id": 1112538,
          "key": "0bbd49ef-75b1-4303-b70c-c9581161e439",
          "title": "Demo: Exercise 6: Building the S3 to Redshift DAG",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "0bbd49ef-75b1-4303-b70c-c9581161e439",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115308,
              "key": "5fdbb8ef-099a-4ed9-b691-011088d74917",
              "title": "Conclusion And Demo 6",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "Wc5WhGwHnZc",
                "china_cdn_id": "Wc5WhGwHnZc.mp4"
              }
            }
          ]
        },
        {
          "id": 1112544,
          "key": "4b0344c7-2f1b-4132-b70a-2335477b5dab",
          "title": "Exercise 6: Build the S3 to Redshift DAG",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "4b0344c7-2f1b-4132-b70a-2335477b5dab",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115315,
              "key": "804e41aa-8a62-4c43-91a9-393882d4582b",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "r766469c817261xREACTblube3pv",
              "pool_id": "airflow",
              "view_id": "react-vif5t",
              "gpu_capable": false,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": {
                      "id": "mldatasets",
                      "paths": [
                        {
                          "src": "/",
                          "dest": "/data/"
                        }
                      ],
                      "mountWarnUntil": 0
                    },
                    "port": 3000,
                    "ports": [],
                    "userCode": "",
                    "openFiles": [
                      "/home/workspace/airflow/dags/lesson1_exercises/exercise6.py"
                    ],
                    "showFiles": true,
                    "allowClose": true,
                    "allowSubmit": false,
                    "terminalTitle": "BASH",
                    "actionButtonText": "Access Airflow",
                    "openTerminalOnStartup": true
                  },
                  "kind": "react"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        },
        {
          "id": 1112529,
          "key": "045f09c3-d227-4ac0-be39-902247c8d378",
          "title": "Solution 6: Build the S3 to Redshift DAG",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "045f09c3-d227-4ac0-be39-902247c8d378",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115283,
              "key": "31fb32fd-e4f3-45ca-af6a-4c6a9e925f00",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Solution 6: Build the S3 to Redshift Dag\n\nBelow is the solution for Exercise 6: Build the S3 to Redshift Dag.\n```\nimport datetime\nimport logging\n\nfrom airflow import DAG\nfrom airflow.contrib.hooks.aws_hook import AwsHook\nfrom airflow.hooks.postgres_hook import PostgresHook\nfrom airflow.operators.postgres_operator import PostgresOperator\nfrom airflow.operators.python_operator import PythonOperator\n\nimport sql_statements\n\n\ndef load_data_to_redshift(*args, **kwargs):\n    aws_hook = AwsHook(\"aws_credentials\")\n    credentials = aws_hook.get_credentials()\n    redshift_hook = PostgresHook(\"redshift\")\n    redshift_hook.run(sql.COPY_ALL_TRIPS_SQL.format(credentials.access_key, credentials.secret_key))\n\n\ndag = DAG(\n    'lesson1.exercise6',\n    start_date=datetime.datetime.now()\n)\n\ncreate_table = PostgresOperator(\n    task_id=\"create_table\",\n    dag=dag,\n    postgres_conn_id=\"redshift\",\n    sql=sql_statements.CREATE_TRIPS_TABLE_SQL\n)\n\ncopy_task = PythonOperator(\n    task_id='load_from_s3_to_redshift',\n    dag=dag,\n    python_callable=load_data_to_redshift\n)\n\nlocation_traffic_task = PostgresOperator(\n    task_id=\"calculate_location_traffic\",\n    dag=dag,\n    postgres_conn_id=\"redshift\",\n    sql=sql_statements.LOCATION_TRAFFIC_SQL\n)\n\ncreate_table >> copy_task\ncopy_task >> location_traffic_task\n```",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 1112520,
          "key": "8cbed96c-27da-4c3b-97f5-cff12d188e92",
          "title": "Conclusion",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "8cbed96c-27da-4c3b-97f5-cff12d188e92",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 1115267,
              "key": "f41be929-ee0c-459e-a64e-e1ecc881e591",
              "title": "15  Conclusion V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "TRdlpeKrRhM",
                "china_cdn_id": "TRdlpeKrRhM.mp4"
              }
            }
          ]
        }
      ]
    }
  },
  "_deprecated": [
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "starter_files",
      "reason": "prefer master_archive_id"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "starter_files",
      "reason": "prefer master_archive_id"
    },
    {
      "name": "starter_files",
      "reason": "prefer master_archive_id"
    },
    {
      "name": "starter_files",
      "reason": "prefer master_archive_id"
    },
    {
      "name": "starter_files",
      "reason": "prefer master_archive_id"
    },
    {
      "name": "starter_files",
      "reason": "prefer master_archive_id"
    },
    {
      "name": "starter_files",
      "reason": "prefer master_archive_id"
    }
  ]
}