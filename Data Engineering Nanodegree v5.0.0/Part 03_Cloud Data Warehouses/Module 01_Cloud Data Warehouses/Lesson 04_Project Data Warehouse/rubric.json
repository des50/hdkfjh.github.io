{
  "id": 2501,
  "project_id": 574,
  "upload_types": [
    "repo",
    "zip"
  ],
  "file_filter_regex": "\\A(?!(((.*/)?(__MACOSX|\\.git|node_modules|bower_components|jspm_packages|\\.idea|build|.ipynb_checkpoints|\\.Trash-0|logs)(\\Z|/))))((.*\\.(js|css|py|html|htm|txt|md|markdown|sql|swift|java|gradle|xml|rst|yml|yaml|rmd|pdf|docx)\\Z)|((.*/)?(README|Readme|readme|Makefile)\\Z))",
  "nomination_eligible": false,
  "stand_out": "- Add data quality checks\n- Create a dashboard for analytic queries on your new database",
  "hide_criteria": false,
  "created_at": "2019-02-15T23:49:50.782Z",
  "updated_at": "2020-04-03T16:30:33.299Z",
  "hashtag": "",
  "max_upload_size_mb": 500,
  "estimated_sla": null,
  "project_assistant_enabled": false,
  "available_for_cert_project": false,
  "language": "en-us",
  "ndkeys": [
    "nd027",
    "nd027-beta",
    "nd027-ent",
    "nd027-ent-rbs",
    "nd027-mena-connect",
    "nd025-ent-shell",
    "nd025-shell"
  ],
  "coursekeys": [],
  "is_career": false,
  "sections": [
    {
      "id": 5419,
      "name": "Table Creation",
      "created_at": "2019-02-27T06:13:52.175Z",
      "updated_at": "2019-02-27T06:19:50.643Z",
      "deleted_at": null,
      "position": 0,
      "rubric_id": 2501,
      "rubric_items": [
        {
          "id": 15596,
          "section_id": 5419,
          "passed_description": "The script, create_tables.py, runs in the terminal without errors. The script successfully connects to the Sparkify database, drops any tables if they exist, and creates the tables.",
          "exceeded_description": null,
          "created_at": "2019-02-27T06:14:06.169Z",
          "updated_at": "2019-02-27T06:14:58.699Z",
          "deleted_at": null,
          "optional": false,
          "position": 0,
          "criteria": "Table creation script runs without errors.",
          "exceedable": false
        },
        {
          "id": 15598,
          "section_id": 5419,
          "passed_description": "CREATE statements in sql_queries.py specify all columns for both the songs and logs staging tables with the right data types and conditions.",
          "exceeded_description": null,
          "created_at": "2019-02-27T06:15:52.759Z",
          "updated_at": "2019-02-27T06:17:44.287Z",
          "deleted_at": null,
          "optional": false,
          "position": 1,
          "criteria": "Staging tables are properly defined.",
          "exceedable": false
        },
        {
          "id": 15597,
          "section_id": 5419,
          "passed_description": "CREATE statements in sql_queries.py specify all columns for each of the five tables with the right data types and conditions.",
          "exceeded_description": null,
          "created_at": "2019-02-27T06:14:58.969Z",
          "updated_at": "2019-02-27T06:17:44.308Z",
          "deleted_at": null,
          "optional": false,
          "position": 2,
          "criteria": "Fact and dimensional tables for a star schema are properly defined.",
          "exceedable": false
        }
      ]
    },
    {
      "id": 5365,
      "name": "ETL",
      "created_at": "2019-02-19T19:56:28.451Z",
      "updated_at": "2019-02-27T06:19:50.648Z",
      "deleted_at": null,
      "position": 1,
      "rubric_id": 2501,
      "rubric_items": [
        {
          "id": 15479,
          "section_id": 5365,
          "passed_description": "The script, `etl.py`, runs in the terminal without errors. The script connects to the Sparkify redshift database, loads `log_data` and `song_data` into staging tables, and transforms them into the five tables.",
          "exceeded_description": null,
          "created_at": "2019-02-19T19:58:00.056Z",
          "updated_at": "2019-02-27T06:36:34.413Z",
          "deleted_at": null,
          "optional": false,
          "position": 0,
          "criteria": "ETL script runs without errors.",
          "exceedable": false
        },
        {
          "id": 15595,
          "section_id": 5365,
          "passed_description": "INSERT statements are correctly written for each table and handles duplicate records where appropriate. Both staging tables are used to insert data into the songplays table.",
          "exceeded_description": null,
          "created_at": "2019-02-27T06:09:38.905Z",
          "updated_at": "2019-02-27T06:13:43.957Z",
          "deleted_at": null,
          "optional": false,
          "position": 1,
          "criteria": "ETL script properly processes transformations in Python.",
          "exceedable": false
        }
      ]
    },
    {
      "id": 5364,
      "name": "Code Quality",
      "created_at": "2019-02-19T19:56:18.323Z",
      "updated_at": "2019-02-27T06:19:50.652Z",
      "deleted_at": null,
      "position": 2,
      "rubric_id": 2501,
      "rubric_items": [
        {
          "id": 15477,
          "section_id": 5364,
          "passed_description": "The README file includes a summary of the project, how to run the Python scripts, and an explanation of the files in the repository. Comments are used effectively and each function has a docstring.",
          "exceeded_description": null,
          "created_at": "2019-02-19T19:56:37.483Z",
          "updated_at": "2019-02-19T19:57:34.656Z",
          "deleted_at": null,
          "optional": false,
          "position": 0,
          "criteria": "The project shows proper use of documentation.",
          "exceedable": false
        },
        {
          "id": 15478,
          "section_id": 5364,
          "passed_description": "Scripts have an intuitive, easy-to-follow structure with code separated into logical functions. Naming for variables and functions follows the PEP8 style guidelines.",
          "exceeded_description": null,
          "created_at": "2019-02-19T19:57:34.959Z",
          "updated_at": "2019-02-19T19:57:59.819Z",
          "deleted_at": null,
          "optional": false,
          "position": 1,
          "criteria": "The project code is clean and modular.",
          "exceedable": false
        }
      ]
    }
  ],
  "project": {
    "id": 574,
    "name": "Data Warehouse",
    "nanodegree_key": "nd027",
    "is_cert_project": false,
    "audit_project_id": null,
    "hashtag": null,
    "audit_rubric_id": 2899,
    "entitlement_required": false,
    "is_career": false,
    "recruitment_family_id": 5,
    "created_at": "2019-02-12T00:25:30.752Z",
    "updated_at": "2021-04-01T16:37:40.517Z",
    "price": "7.0",
    "ungradeable_price": "3.0",
    "audit_price": "0.0"
  }
}