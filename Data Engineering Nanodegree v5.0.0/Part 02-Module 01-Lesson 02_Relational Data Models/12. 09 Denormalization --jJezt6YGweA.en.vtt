WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.754
So, now, we're going to start talking about denormalization.

00:00:04.754 --> 00:00:08.160
We just spent a lot of time focused on normalization.

00:00:08.160 --> 00:00:10.484
Now, it's time to move to denormalization.

00:00:10.484 --> 00:00:12.029
Again, I want to stress,

00:00:12.029 --> 00:00:18.960
these really are the most important concepts when we're doing relational data modeling.

00:00:18.960 --> 00:00:21.089
So, if you understand these ones or you have

00:00:21.089 --> 00:00:25.274
a good understanding of these fundamental concepts,

00:00:25.274 --> 00:00:27.479
you're going to be in great shape to be able to

00:00:27.480 --> 00:00:30.480
do data modeling for relational databases.

00:00:30.480 --> 00:00:33.689
So, the denormalization is the process of trying

00:00:33.689 --> 00:00:36.269
to improve the read performance of a database at

00:00:36.270 --> 00:00:42.495
the expense of losing some write performance by adding redundant copies of the data.

00:00:42.494 --> 00:00:47.414
So, the process of denormalization is all about performance.

00:00:47.414 --> 00:00:51.710
Joints on the database allow for outstanding flexibility,

00:00:51.710 --> 00:00:53.990
but they are extremely slow.

00:00:53.990 --> 00:00:57.545
So, we saw that in the last exercise in the last demo,

00:00:57.545 --> 00:01:01.370
we were able to get our table all the way to third normal form,

00:01:01.369 --> 00:01:04.129
but then we were able to get all the information that we

00:01:04.129 --> 00:01:07.045
originally had in our first table by doing joints.

00:01:07.045 --> 00:01:12.060
At one point, we were able to get everything with two different joints,

00:01:12.060 --> 00:01:13.560
on three different tables.

00:01:13.560 --> 00:01:15.960
So, that's incredible flexibility,

00:01:15.959 --> 00:01:17.704
and it's really fantastic that we have that.

00:01:17.704 --> 00:01:19.534
But they are slow.

00:01:19.534 --> 00:01:22.834
If you're dealing with heavy reads on your database,

00:01:22.834 --> 00:01:25.459
you may want to think about denormalizing your table.

00:01:25.459 --> 00:01:28.909
Denormalization comes after normalization.

00:01:28.909 --> 00:01:30.439
So, this is again,

00:01:30.439 --> 00:01:31.879
this is all about a process.

00:01:31.879 --> 00:01:36.454
You get your table to normalize form and from there, you denormalize it.

00:01:36.454 --> 00:01:39.890
Denormalization may also require more space on

00:01:39.890 --> 00:01:43.700
your system and there's now going to be more copies of the data.

00:01:43.700 --> 00:01:45.715
While this shouldn't be ignored,

00:01:45.715 --> 00:01:50.255
has become less of a concern as space has become less expensive,

00:01:50.254 --> 00:01:52.894
and it is not really a limiting factor.

00:01:52.894 --> 00:01:54.979
When we do denormalization,

00:01:54.980 --> 00:01:57.290
we want to do a logical design change.

00:01:57.290 --> 00:02:02.840
That means we're going to model our data differently so that we have denormalized tables.

00:02:02.840 --> 00:02:06.650
So, the designer is in charge of keeping the data consistent.

00:02:06.650 --> 00:02:09.284
The reads will be fast, the select statement,

00:02:09.284 --> 00:02:10.634
but the writes will be slower,

00:02:10.634 --> 00:02:13.204
which is the insert, update, and delete statement.

00:02:13.205 --> 00:02:16.055
We've talked a lot about getting our data consistent,

00:02:16.055 --> 00:02:20.314
but what does this really mean especially when dealing with denormalization?

00:02:20.314 --> 00:02:22.789
Once you add more copies of that data,

00:02:22.789 --> 00:02:25.609
that means you'll need to make sure that each one of those copies

00:02:25.610 --> 00:02:28.595
is updated or deleted at the same time.

00:02:28.594 --> 00:02:32.194
For example, if you have two tables with a column,

00:02:32.194 --> 00:02:34.775
address of customer, then you will need to do

00:02:34.775 --> 00:02:37.849
two insert statements when adding my address.

00:02:37.849 --> 00:02:39.989
Or if you're updating my address,

00:02:39.990 --> 00:02:42.695
you will need to change that in two places.

00:02:42.694 --> 00:02:46.204
Well, this is not difficult in theory or on small projects.

00:02:46.205 --> 00:02:48.350
This gets very complicated when we're talking about

00:02:48.349 --> 00:02:51.625
large datasets with many applications using the data.

00:02:51.625 --> 00:02:54.680
It's just something that you need to be aware of and make sure that you're

00:02:54.680 --> 00:02:58.145
handling if you want to use denormalization.

00:02:58.145 --> 00:03:00.830
Let's talk about an example here with our two tables.

00:03:00.830 --> 00:03:05.065
Here, we have a table called customer and a table called shipping.

00:03:05.064 --> 00:03:08.359
Now, remember, denormalization is all about performance.

00:03:08.360 --> 00:03:12.590
Let's say we're getting heavy reads from both of these tables,

00:03:12.590 --> 00:03:14.810
trying to get information about how much

00:03:14.810 --> 00:03:18.830
our customer spent and the kinds of items that we need to ship to their house,

00:03:18.830 --> 00:03:20.150
maybe something that they've purchased.

00:03:20.150 --> 00:03:23.855
Now, we could have these all in different tables

00:03:23.854 --> 00:03:28.294
split up that then we're using a lot of joints to aggregate all the data together.

00:03:28.294 --> 00:03:31.504
Or we could just separate it out and have

00:03:31.504 --> 00:03:35.539
two tables with duplicate sets of information, right?

00:03:35.539 --> 00:03:40.280
Both tables have the name column and both columns have the city column, and that's okay.

00:03:40.280 --> 00:03:43.870
Duplicate data is okay in a denormalized form.

00:03:43.870 --> 00:03:49.340
From there, we'll have information that's specific to that concept, like shipping.

00:03:49.340 --> 00:03:52.280
So, I'm going to ship a particular item or my customer,

00:03:52.280 --> 00:03:54.960
he spent a particular amount.

