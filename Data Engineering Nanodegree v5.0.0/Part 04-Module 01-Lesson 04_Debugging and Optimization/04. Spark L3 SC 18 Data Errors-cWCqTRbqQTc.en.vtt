WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.475
They may process big data files.

00:00:02.475 --> 00:00:05.310
Some of the rows can easily broken.

00:00:05.309 --> 00:00:08.984
They might have missing fields or have data

00:00:08.984 --> 00:00:13.425
that's malformed or incorrect in some other unexpected way.

00:00:13.425 --> 00:00:16.859
By Spark [inaudible] missing data fairly well.

00:00:16.859 --> 00:00:19.425
Populating these fields with nulls.

00:00:19.425 --> 00:00:25.755
This also applies if you try to do something with a missing field, nulls remain nulls.

00:00:25.754 --> 00:00:28.890
Let's see what happens if you try to the file

00:00:28.890 --> 00:00:33.039
that has records that don't conform to the schema.

00:00:34.880 --> 00:00:40.010
A new field corrupt record has a period.

00:00:40.009 --> 00:00:45.335
This is the same input file that we used before.

00:00:45.335 --> 00:00:48.399
It just has a few broken records.

00:00:48.399 --> 00:00:50.174
Then, we load it.

00:00:50.174 --> 00:00:55.349
We see that we got this corrupted record column showing up.

00:00:55.350 --> 00:00:57.390
In this first example,

00:00:57.390 --> 00:00:59.655
it's value is none.

00:00:59.655 --> 00:01:03.149
In the second record is the same.

00:01:03.149 --> 00:01:06.989
So let's try to find a corrupt record.

00:01:06.989 --> 00:01:17.310
To do that, I'm just filtering the logs3 data frame to see where is this column NotNull.

00:01:17.310 --> 00:01:21.000
All right. We got a record.

00:01:21.000 --> 00:01:27.539
So it looks like that the corrupt record field contains

00:01:27.539 --> 00:01:34.670
everything and all of the other columns have a non-value.

00:01:34.670 --> 00:01:43.930
It looks like that this record has a string value without quotes as its timestamp.

00:01:43.930 --> 00:01:46.535
The trial is the JSON format.

00:01:46.534 --> 00:01:50.659
That's why it became corrupted record.

00:01:50.659 --> 00:01:53.314
We just couldn't read it.

00:01:53.314 --> 00:01:59.170
It's reassuring that completely broken records are not part of our data set.

00:01:59.170 --> 00:02:02.435
We might want to have a higher quality standard.

00:02:02.435 --> 00:02:06.424
For example, just because a string is properly coded,

00:02:06.424 --> 00:02:09.484
it still should not be used as a timestamp.

00:02:09.485 --> 00:02:14.475
All of the other values in this column are of type long.

00:02:14.474 --> 00:02:16.289
In the next video,

00:02:16.289 --> 00:02:20.069
we will see how to get the check in place,

00:02:20.069 --> 00:02:28.199
and see how many records don't confirm to some sort of rule we want to enforce.

