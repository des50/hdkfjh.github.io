WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.379
Over the years, people have tried to build data warehouses differently,

00:00:04.379 --> 00:00:06.435
optimizing for different factors.

00:00:06.434 --> 00:00:12.149
There were many so-called models or architectures for building a data warehouse.

00:00:12.150 --> 00:00:16.964
Perhaps some of the most famous designs

00:00:16.964 --> 00:00:20.640
or architectures are the Kimball architecture and the Inmon architecture,

00:00:20.640 --> 00:00:22.635
the say Corporate Information Factory.

00:00:22.635 --> 00:00:25.095
So, let's take them one by one.

00:00:25.094 --> 00:00:31.629
So, in the Kimball's bus architecture we have the source transaction system,

00:00:32.509 --> 00:00:36.789
we have an ETL process.

00:00:36.829 --> 00:00:44.629
Here this area actually never gets exposed to the end-user at all.

00:00:44.630 --> 00:00:53.265
What happens is we transform the data and we put it into dimensional model.

00:00:53.265 --> 00:00:59.864
Here, the dimensional model facts are not aggregated,

00:00:59.863 --> 00:01:03.049
they are on the what they call atomic level which means we should

00:01:03.049 --> 00:01:06.679
come to a number that we cannot divide further.

00:01:06.680 --> 00:01:09.740
We can also pre-aggregate it but

00:01:09.739 --> 00:01:15.319
the atomic level has to be always there in case we need to go to the lowest level.

00:01:15.319 --> 00:01:20.119
It should be organized by business processes or departments.

00:01:20.120 --> 00:01:22.280
That's actually what's meant here which means

00:01:22.280 --> 00:01:25.820
the salespeople would know exactly where to go,

00:01:25.819 --> 00:01:27.169
the marketing people would know,

00:01:27.170 --> 00:01:29.525
the HR would know where to go and so forth.

00:01:29.525 --> 00:01:34.490
The most also important property here is

00:01:34.489 --> 00:01:41.269
the idea of conformed dimensions which means that if I did a date dimension,

00:01:41.269 --> 00:01:44.299
I use it across all departments.

00:01:44.299 --> 00:01:47.179
So, I try to generalize and build

00:01:47.180 --> 00:01:52.660
all my dimensions in a way that is usable by the whole organization.

00:01:52.659 --> 00:01:56.959
It needs some careful design of course to be able to do something like that.

00:01:56.959 --> 00:02:01.984
Again the whole point always is ease of use and great performance.

00:02:01.984 --> 00:02:03.819
Then we have the application here.

00:02:03.819 --> 00:02:07.279
Sometimes we call this area the front room because this area is

00:02:07.280 --> 00:02:10.909
exposed to end-users and this is the backroom.

00:02:10.909 --> 00:02:16.930
Sometimes Kimball's gives the analogy of the kitchen and the dining room.

00:02:16.930 --> 00:02:21.110
So, that is the kitchen where you actually prepare things to be served here

00:02:21.110 --> 00:02:26.220
and you can have them served to your customer in the dining room.

00:02:26.479 --> 00:02:32.269
You actually go and give to your users what's known as the bus matrix.

00:02:32.270 --> 00:02:34.860
So, you know that for each business process,

00:02:34.860 --> 00:02:36.870
it's going to use this dimension, this dimension,

00:02:36.870 --> 00:02:39.890
this dimension but the important thing is that the date dimension,

00:02:39.889 --> 00:02:41.464
or the product dimension,

00:02:41.465 --> 00:02:44.689
or the store dimension should be all over

00:02:44.689 --> 00:02:51.120
across business departments and business processes, it should be the same.

00:02:51.120 --> 00:02:57.425
The ETL here is actually a little bit more involved

00:02:57.425 --> 00:03:04.085
than our copy from sequel to sequel because we get the data from its source.

00:03:04.085 --> 00:03:07.099
Of course we have many sources so it's a bit

00:03:07.099 --> 00:03:11.544
hybrid and then we possibly delete the old state.

00:03:11.544 --> 00:03:15.000
Sometimes the OLTP cannot hold a lot of

00:03:15.000 --> 00:03:18.569
state and we need that state so not only do we copy

00:03:18.569 --> 00:03:25.215
but we actually move data which is unneeded state before OLTP.

00:03:25.215 --> 00:03:27.390
Then for the transformation,

00:03:27.389 --> 00:03:30.349
we should be able to know how to integrate

00:03:30.349 --> 00:03:34.254
multiple data sources that might not be even aware of each other.

00:03:34.254 --> 00:03:37.799
Possibly, we can clean inconsistencies, duplication,

00:03:37.799 --> 00:03:41.780
missing values, and clean things up.

00:03:41.780 --> 00:03:45.500
We can also produce diagnostic metadata like we can say,

00:03:45.500 --> 00:03:48.949
"Actually when we get this data from that source,

00:03:48.949 --> 00:03:50.899
we found lots of inconsistencies."

00:03:50.900 --> 00:03:53.270
So, the output of the translation process

00:03:53.270 --> 00:03:56.600
itself might even be reported back as a metric that

00:03:56.599 --> 00:03:59.419
this source of data is not really clean

00:03:59.419 --> 00:04:03.514
or we get lots of duplicated data from it and so forth.

00:04:03.514 --> 00:04:08.639
Then finally, we go and load that into the dimension.

