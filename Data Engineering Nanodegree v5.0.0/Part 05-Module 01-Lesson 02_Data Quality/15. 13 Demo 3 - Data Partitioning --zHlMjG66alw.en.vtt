WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.609
So now, we're going to do one more demo.

00:00:02.609 --> 00:00:05.459
This demo, I'm going to show you how to modify our DAG to load data

00:00:05.459 --> 00:00:08.490
month by month instead of loading all of data all at once,

00:00:08.490 --> 00:00:11.429
this is a form of time partitioning that we can apply to our DAG.

00:00:11.429 --> 00:00:14.070
So, in the previous example,

00:00:14.070 --> 00:00:18.750
if you actually look at the code, we've got to pull up.

00:00:18.750 --> 00:00:21.945
So, we're back in Lesson 2 Demo 2,

00:00:21.945 --> 00:00:23.535
whenever left this screen.

00:00:23.535 --> 00:00:26.370
So, if I actually look at the code that was being

00:00:26.370 --> 00:00:30.000
executed when I say load the trips data from S3 to Redshift,

00:00:30.000 --> 00:00:32.475
I'm going to go ahead and view the log,

00:00:32.475 --> 00:00:36.329
we can see here that it's just copying all the data.

00:00:36.329 --> 00:00:37.859
The data is unpartitioned,

00:00:37.859 --> 00:00:40.719
this is all the data for 2018.

00:00:41.570 --> 00:00:44.655
So now, I'm going to go ahead and fix that.

00:00:44.655 --> 00:00:47.789
First, I'm going to turn off Lesson 2 Demo 2,

00:00:47.789 --> 00:00:51.879
then we're going to turn on Lesson 2 Demo 3 in just a moment.

00:00:52.100 --> 00:00:56.145
So, real quick, I'm going to jump into Demo 3,

00:00:56.145 --> 00:01:00.710
and this demo is slightly modified from what you've seen in the past.

00:01:00.710 --> 00:01:03.649
So, when you guys do exercise three,

00:01:03.649 --> 00:01:08.314
you'll actually be modifying the code to change

00:01:08.314 --> 00:01:14.194
the time frame that the data is loaded on to be month-by-month in Redshift.

00:01:14.194 --> 00:01:15.904
In this example though,

00:01:15.905 --> 00:01:20.260
I'm actually going to modify our SQL command to analyze the data month by month,

00:01:20.260 --> 00:01:23.225
so you're going to have a slightly different exercise.

00:01:23.224 --> 00:01:27.274
So, what we have right now is a location traffic task.

00:01:27.275 --> 00:01:29.495
This task has an ID,

00:01:29.495 --> 00:01:31.740
a DAG and reasoning the Redshift connection,

00:01:31.739 --> 00:01:33.420
pretty standard so far.

00:01:33.420 --> 00:01:36.375
Finally, we have this SQL statement down here.

00:01:36.375 --> 00:01:38.450
So, this may look a little confusing.

00:01:38.450 --> 00:01:43.165
What you're seeing here is a Python formatting string.

00:01:43.165 --> 00:01:46.005
We have sql.LOCATION_TRAFFIC_SQL.

00:01:46.004 --> 00:01:47.939
So, if we look at this command,

00:01:47.939 --> 00:01:49.575
if you're curious what it is,

00:01:49.575 --> 00:01:51.795
we can open that code.

00:01:51.795 --> 00:01:54.480
Open it in the file,

00:01:54.480 --> 00:01:56.445
and you can see down here,

00:01:56.444 --> 00:01:58.649
we have LOCATION_TRAFFIC_SQL, so you can see

00:01:58.650 --> 00:02:01.440
exactly what the LOCATION_TRAFFIC_SQL is doing.

00:02:01.439 --> 00:02:03.344
Dropping the table, creating it.

00:02:03.344 --> 00:02:06.064
Then it's creating a table by performing

00:02:06.064 --> 00:02:11.734
a select from counts on the number of departures and number of arrivals.

00:02:11.735 --> 00:02:14.405
But what if I just wanted to do those selects

00:02:14.405 --> 00:02:17.405
based on data from a particular time period?

00:02:17.405 --> 00:02:20.379
Say, for the time period of this run.

00:02:20.379 --> 00:02:23.240
So, what I'm going to do is I'm going to render in

00:02:23.240 --> 00:02:27.230
the SQL statement that we were just looking at here, this LOCATION_TRAFFIC_SQL,

00:02:27.229 --> 00:02:33.844
so I'm going to render in this LOCATION_TRAFFIC_SQL right here,

00:02:33.844 --> 00:02:35.580
that's what the string is doing so far.

00:02:35.580 --> 00:02:38.015
So so far, we haven't really done anything.

00:02:38.014 --> 00:02:40.099
All we've done is created a string that has

00:02:40.099 --> 00:02:43.224
the SQL statement that we've already seen before.

00:02:43.224 --> 00:02:46.370
What I want to do is add a where clause so that we're

00:02:46.370 --> 00:02:49.235
only looking at data for time periods of interest.

00:02:49.235 --> 00:02:52.760
So first, I'm going to say where and then we're

00:02:52.759 --> 00:02:56.134
going to have to figure out exactly what the datetime is.

00:02:56.134 --> 00:03:02.465
So, I think I need to look at the actual name of the field,

00:03:02.465 --> 00:03:04.625
so the name of the field is end time,

00:03:04.625 --> 00:03:06.139
we're going to do it by end time.

00:03:06.139 --> 00:03:09.904
So, I'm looking at the trips table, we're going to say,

00:03:09.905 --> 00:03:14.620
Where end time is greater than,

00:03:14.620 --> 00:03:18.200
and this syntax can be a little confusing,

00:03:18.199 --> 00:03:20.514
and I'm going to explain this in just a moment,

00:03:20.514 --> 00:03:25.264
where the end time is greater than previous run.

00:03:25.264 --> 00:03:29.489
So, previous ds stands for the last time this DAG ran,

00:03:29.490 --> 00:03:35.025
and we want the end time

00:03:35.025 --> 00:03:41.469
to be less than the next time the DAG is going to run.

00:03:41.469 --> 00:03:43.960
So, real quick, let's review this one more time.

00:03:43.960 --> 00:03:46.675
So, we want to run this LOCATION_TRAFFIC_SQL,

00:03:46.675 --> 00:03:52.450
but we only want to run our analysis where the end time is greater than the runtime of

00:03:52.449 --> 00:03:56.069
our previous execution of our DAG and

00:03:56.069 --> 00:04:00.844
the end time is less than the execution of our next DAG run.

00:04:00.844 --> 00:04:02.734
How did I know what these fields are?

00:04:02.735 --> 00:04:03.950
Where do these come from?

00:04:03.949 --> 00:04:06.244
So, if you remember from lesson one,

00:04:06.245 --> 00:04:10.335
we talked about templating our DAGs.

00:04:10.335 --> 00:04:15.200
So, I'm going to jump back to the browser and open up my API reference.

00:04:15.199 --> 00:04:19.750
So, you can find this API reference in your lesson one and its exercises,

00:04:19.750 --> 00:04:24.589
and we can see here I'm using previous ds and next ds.

00:04:24.589 --> 00:04:29.439
Previous ds will give us the previous execution data of a DAG in the format year, month,

00:04:29.439 --> 00:04:35.110
date, and next ds will give us the next execution date in the format year, month, date.

00:04:35.110 --> 00:04:39.194
So, I want to use these two variables.

00:04:39.194 --> 00:04:41.084
If we go back to SQL,

00:04:41.084 --> 00:04:45.799
why do we have four of these brackets instead of two?

00:04:45.800 --> 00:04:47.430
That's pretty strange.

00:04:47.430 --> 00:04:50.000
The reason that we have four brackets here is that

00:04:50.000 --> 00:04:52.295
we're going to be formatting this twice,

00:04:52.295 --> 00:04:54.215
so this looks a little confusing.

00:04:54.214 --> 00:04:55.459
So first, we're going to run

00:04:55.459 --> 00:04:58.714
the Python format which is going to insert the SQL statement.

00:04:58.714 --> 00:05:02.754
That's going to remove two of these brackets,

00:05:02.754 --> 00:05:06.560
but we still need Airflow to inject the execution date,

00:05:06.560 --> 00:05:11.415
previous and next execution date into the SQL statement when it runs.

00:05:11.415 --> 00:05:13.490
So, now that we've updated this,

00:05:13.490 --> 00:05:18.074
I'm going to save and go back to Airflow and try running my DAG.

00:05:18.074 --> 00:05:21.495
So, we're going to turn on Lesson 2 Demo 3,

00:05:21.495 --> 00:05:25.100
I'm going to refresh, Airflow should start running a here shortly.

00:05:25.100 --> 00:05:28.145
So, you can see it's a resorted to the tests.

00:05:28.144 --> 00:05:30.939
We're going to jump into Lesson 2 Demo 3,

00:05:30.939 --> 00:05:33.089
and we can see,

00:05:33.089 --> 00:05:35.689
in our graph view that it's already starting to create

00:05:35.689 --> 00:05:39.790
the trips table and now it's loading the data from S3 to Redshift.

00:05:39.790 --> 00:05:44.345
So, now we're onto the new updated calculate location traffic task.

00:05:44.345 --> 00:05:46.560
So, it's currently running.

00:05:47.199 --> 00:05:54.699
We're going to let that finish and now it's complete.

00:05:54.699 --> 00:05:58.354
So, let's take a look at how it rendered out those dates.

00:05:58.355 --> 00:06:02.660
So, I'm going to click on calculate_location_traffic,

00:06:02.660 --> 00:06:05.705
then I'm going to go up to "View Log"

00:06:05.704 --> 00:06:09.250
or I could look at "Rendered" let's pull up Rendered.

00:06:09.250 --> 00:06:15.185
We scroll down, we can see that we have begin and we have nowhere.

00:06:15.185 --> 00:06:18.780
But if we go to Log, we should see that in there.

00:06:19.040 --> 00:06:21.960
So, you can see in our statement here,

00:06:21.959 --> 00:06:23.294
the formatting is a little off,

00:06:23.295 --> 00:06:28.790
I apologize for that, but you can see that this is the SQL statement in our SQL file,

00:06:28.790 --> 00:06:31.750
which is the one we've already run a number of times before,

00:06:31.750 --> 00:06:34.139
but we also have this new where clause,

00:06:34.139 --> 00:06:38.000
where end time is greater than 2017 December 1st,

00:06:38.000 --> 00:06:41.915
and end time is less than 2018 February 1st.

00:06:41.915 --> 00:06:46.439
So, this would give us the data that we actually need to process.

