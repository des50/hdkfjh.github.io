WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.710
Well, we've already covered how to set a schedule on an airflow DAG in lesson one.

00:00:04.710 --> 00:00:06.599
We didn't cover how airflow uses

00:00:06.599 --> 00:00:10.515
this schedule interval to create historical DAG runs and backfill data.

00:00:10.515 --> 00:00:13.500
Whenever the start of a DAG is in the past,

00:00:13.500 --> 00:00:15.629
in a time difference between the start_date and

00:00:15.630 --> 00:00:18.644
now includes more than one schedule intervals,

00:00:18.644 --> 00:00:21.370
airflow will automatically schedule and execute

00:00:21.370 --> 00:00:24.705
a DAG run to satisfy each one of those intervals.

00:00:24.704 --> 00:00:28.019
Here's an example from lesson one, exercise three.

00:00:28.019 --> 00:00:31.019
On the far left, you can see the first one of our DAG,

00:00:31.019 --> 00:00:33.420
where are the start_date arrow is pointing.

00:00:33.420 --> 00:00:35.490
So, here would be the start of the DAG.

00:00:35.490 --> 00:00:40.130
So, the start_date here is now minus 60 days.

00:00:40.130 --> 00:00:42.265
We have a monthly interval.

00:00:42.265 --> 00:00:46.755
So, this would indicate that would be the start_date, okay?

00:00:46.755 --> 00:00:48.780
The far left is your start_date.

00:00:48.780 --> 00:00:50.539
On the far right, you can see

00:00:50.539 --> 00:00:53.179
the most recent run of the DAG where the now arrow is pointing.

00:00:53.179 --> 00:00:54.619
So, that would be here.

00:00:54.619 --> 00:00:57.504
So, this would be the most recent run of our DAG.

00:00:57.505 --> 00:01:01.415
Every column between start_date and now

00:01:01.414 --> 00:01:05.900
represents an interval that a DAG run that airflow scheduled as backfill.

00:01:05.900 --> 00:01:11.000
So, we can see the schedule interval as the period between two of these DAG runs.

00:01:11.000 --> 00:01:14.245
So, each one of these columns represents a DAG run.

00:01:14.245 --> 00:01:19.750
Basically, the time spacing between each one of these runs is the schedule_interval.

00:01:19.750 --> 00:01:22.730
This feature is useful in almost all enterprise settings,

00:01:22.730 --> 00:01:24.650
where companies have established years of

00:01:24.650 --> 00:01:27.395
data that may need to be retroactively analyzed.

00:01:27.394 --> 00:01:30.679
For example, we just recently talked about comparing

00:01:30.680 --> 00:01:33.975
marketing data to trip data over a period of time.

00:01:33.974 --> 00:01:36.094
We've used November as an example.

00:01:36.094 --> 00:01:40.569
If I have five years of marketing data and I have five years of trip data,

00:01:40.569 --> 00:01:43.729
even if I just set up an analysis and airflow,

00:01:43.730 --> 00:01:48.290
I can actually set up my analysis to look at a day's worth of data at a time and use

00:01:48.290 --> 00:01:51.650
airflow's backfill feature to make sure that I can have

00:01:51.650 --> 00:01:55.835
a robust pipeline that will work a day at a time.

00:01:55.834 --> 00:01:57.949
So, if my analysis fails,

00:01:57.950 --> 00:02:02.150
say two years into my 10 years or five years worth of marketing data,

00:02:02.150 --> 00:02:06.290
I don't lose all the data from the start up until that point.

00:02:06.290 --> 00:02:09.500
So, this is a really useful feature and one that we can

00:02:09.500 --> 00:02:13.219
exploit to really make our pipelines robust.

00:02:13.219 --> 00:02:17.080
Finally, airflow pipelines can also have end_dates.

00:02:17.080 --> 00:02:19.200
I mentioned this briefly in the past.

00:02:19.199 --> 00:02:21.530
Perhaps, a dataset only spans a set period of

00:02:21.530 --> 00:02:24.814
time or a project will be going end of life at some point.

00:02:24.814 --> 00:02:27.020
Or perhaps, you've made substantial changes to

00:02:27.020 --> 00:02:30.235
a DAG and you want to have a second reversion of it.

00:02:30.235 --> 00:02:32.840
In both cases, you can use an end_date with

00:02:32.840 --> 00:02:36.680
your pipeline to let airflow know to stop running the pipeline.

00:02:36.680 --> 00:02:39.409
End_dates can also be useful when you want to perform

00:02:39.409 --> 00:02:41.764
an overhaul or redesign of an existing pipeline.

00:02:41.764 --> 00:02:44.419
Update the old pipeline with an end_date and then have

00:02:44.419 --> 00:02:47.329
the new pipeline start on the end_date of the old pipeline.

00:02:47.330 --> 00:02:50.255
So, for example, if this pipeline run from January to

00:02:50.254 --> 00:02:53.719
April and then I wanted to replace this redshift analysis with a new one,

00:02:53.719 --> 00:02:57.439
I might shift my start_date to the same day as the end_date of

00:02:57.439 --> 00:03:02.254
the old pipeline and then not have an end_date so that it runs into the future.

00:03:02.254 --> 00:03:05.939
In the next exercise, you'll have an opportunity to use an end_date.

