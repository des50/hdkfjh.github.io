<!-- udacity2.0 -->
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Reading and Writing to Amazon S3</title>
  <link rel="stylesheet" href="../assets/css/bootstrap.min.css">
  <link rel="stylesheet" href="../assets/css/plyr.css">
  <link rel="stylesheet" href="../assets/css/katex.min.css">
  <link rel="stylesheet" href="../assets/css/jquery.mCustomScrollbar.min.css">
  <link rel="stylesheet" href="../assets/css/styles.css">
  <link rel="shortcut icon" type="image/png" href="../assets/img/udacimak.png" />
</head>

<body>
  <div class="wrapper">
    <nav id="sidebar">
  <div class="sidebar-header">
    <h3>Setting up Spark Clusters with AWS</h3>
  </div>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled components">
    <li class="">
      <a href="01. Introduction.html">01. Introduction</a>
    </li>
    <li class="">
      <a href="02. From Local to Standalone Mode.html">02. From Local to Standalone Mode</a>
    </li>
    <li class="">
      <a href="03. Setup Instructions AWS.html">03. Setup Instructions AWS</a>
    </li>
    <li class="">
      <a href="04. AWS - Install and Configure CLI v2.html">04. AWS - Install and Configure CLI v2</a>
    </li>
    <li class="">
      <a href="05. AWS CLI - Create EMR Cluster.html">05. AWS CLI - Create EMR Cluster</a>
    </li>
    <li class="">
      <a href="06. Using Notebooks on Your Cluster.html">06. Using Notebooks on Your Cluster</a>
    </li>
    <li class="">
      <a href="07. Spark Scripts.html">07. Spark Scripts</a>
    </li>
    <li class="">
      <a href="08. Submitting Spark Scripts.html">08. Submitting Spark Scripts</a>
    </li>
    <li class="">
      <a href="09. Storing and Retrieving Data on the Cloud.html">09. Storing and Retrieving Data on the Cloud</a>
    </li>
    <li class="">
      <a href="10. Reading and Writing to Amazon S3.html">10. Reading and Writing to Amazon S3</a>
    </li>
    <li class="">
      <a href="11. Understanding difference between HDFS and AWS S3.html">11. Understanding difference between HDFS and AWS S3</a>
    </li>
    <li class="">
      <a href="12. Reading and Writing Data to HDFS.html">12. Reading and Writing Data to HDFS</a>
    </li>
    <li class="">
      <a href="13. Recap Local Mode to Cluster Mode.html">13. Recap Local Mode to Cluster Mode</a>
    </li>
  </ul>

  <ul class="sidebar-list list-unstyled CTAs">
    <li>
      <a href="../index.html" class="article">Back to Home</a>
    </li>
  </ul>
</nav>

    <div id="content">
      <header class="container-fluild header">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <div class="align-items-middle">
                <button type="button" id="sidebarCollapse" class="btn btn-toggle-sidebar">
                  <div></div>
                  <div></div>
                  <div></div>
                </button>

                <h1 style="display: inline-block">10. Reading and Writing to Amazon S3</h1>
              </div>
            </div>
          </div>
        </div>
      </header>

      <main class="container">
        <div class="row">
          <div class="col-12">
            <div class="ud-atom">
  <h3><p>S3 Buckets</p></h3>
  <div>
  <h3 id="s3-buckets">S3 Buckets</h3>
<p>With the convenient AWS UI, we can easily mistake AWS S3 (Simple Storage Service) equivalent as Dropbox or even Google Drive. This is not the case for S3. S3 stores an object, and when you identify an object, you need to specify a bucket, and key to identify the object.<br />
For example,</p>
<pre><code>df = spark.read.load(“s3://my_bucket/path/to/file/file.csv”)</code></pre>
<p>From this code, <code>s3://my_bucket</code>is the bucket, and <code>path/to/file/file.csv</code> is the key for the object. Thankfully, if we’re using spark, and all the objects underneath the bucket have the same schema, you can do something like below.</p>
<pre><code>df = spark.read.load(“s3://my_bucket/”)</code></pre>
<p>This will generate a dataframe of all the objects underneath the <code>my_bucket</code> with the same schema.<br />
Pretend some structure in s3 like below:</p>
<pre><code>my_bucket
  |---test.csv
  path/to/
     |--test2.csv
     file/
       |--test3.csv
       |--file.csv</code></pre>
<p>If all the csv files underneath <code>my_bucket</code>, which are <code>test.csv</code>, <code>test2.csv</code>, <code>test3.csv</code>, and <code>file.csv</code> have the same schema, the dataframe will be generated without error, but if there are conflicts in schema between files, then the dataframe will not be generated. As an engineer, you need to be careful on how you organize your data lake.</p>
</div>

</div>
<div class="divider"></div><div class="ud-atom">
  <h3><p>Spark L3 SC 10 Reading And Writing To Amazon S3 Part 2</p></h3>
  <video controls>
  <source src="10. Spark L3 SC 10 Reading And Writing To Amazon S3 Part 2-j4kpT3DQ8i8.mp4" type="video/mp4">

  <track default="true" kind="subtitles" srclang="en" src="10. Spark L3 SC 10 Reading And Writing To Amazon S3 Part 2-j4kpT3DQ8i8.en.vtt" label="en">
</video>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3><p>Spark L3 SC 10 Reading And Writing To Amazon S3 Part 3</p></h3>
  <video controls>
  <source src="10. Spark L3 SC 10 Reading And Writing To Amazon S3 Part 3-yXfb4vwg7aM.mp4" type="video/mp4">

  <track default="true" kind="subtitles" srclang="en" src="10. Spark L3 SC 10 Reading And Writing To Amazon S3 Part 3-yXfb4vwg7aM.en.vtt" label="en">
</video>


</div>
<div class="divider"></div><div class="ud-atom">
  <h3></h3>
  <div>
  <h3 id="link-to-github-repohttpsgithubcomudacitynd027-c3-data-lakes-with-sparktreemastersetting_spark_cluster_in_awsdemo_code-on-demo-code-referred-to-in-video-herehttpsgithubcomudacitynd027-c3-data-lakes-with-sparktreemastersetting_spark_cluster_in_awsdemo_code"><a href="https://github.com/udacity/nd027-c3-data-lakes-with-spark/tree/master/Setting_Spark_Cluster_In_AWS/demo_code" rel="noopener noreferrer" target="_blank">Link to Github Repo</a> on Demo code referred to in video: <a href="https://github.com/udacity/nd027-c3-data-lakes-with-spark/tree/master/Setting_Spark_Cluster_In_AWS/demo_code" rel="noopener noreferrer" target="_blank">HERE</a></h3>
</div>

</div>
<div class="divider"></div>
          </div>

          <div class="col-12">
            <p class="text-right">
              <a href="11. Understanding difference between HDFS and AWS S3.html" class="btn btn-outline-primary mt-4" role="button">Next Concept</a>
            </p>
          </div>
        </div>
      </main>

      <footer class="footer">
        <div class="container">
          <div class="row">
            <div class="col-12">
              <p class="text-center">
                <a href="https://us-udacity.github.io/" target="_blank">【udacity2.0 】If you need more courses, please add wechat：udacity6</a>
              </p>
            </div>
          </div>
        </div>
      </footer>
    </div>
  </div>


  <script src="../assets/js/jquery-3.3.1.min.js"></script>
  <script src="../assets/js/plyr.polyfilled.min.js"></script>
  <script src="../assets/js/bootstrap.min.js"></script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js"></script>
  <script src="../assets/js/katex.min.js"></script>
  <script>
    // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('10. Reading and Writing to Amazon S3')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
</body>

</html>
